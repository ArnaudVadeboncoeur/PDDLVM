{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(10)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(10)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=6000)])\n",
    "\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "except:\n",
    "  # Invalid device or cannot modify logical devices once initialized.\n",
    "  pass\n",
    "\n",
    "import time\n",
    "\n",
    "from vpe.utilities import tf, tfp, np, plt, tfb, floatf, tffloat, tfint, updateTfFloat,  _0\n",
    "updateTfFloat ( tf.float32 )\n",
    "\n",
    "from vpe.poisson1DPDEState import PDE_State\n",
    "from vpe.poisson1DSolver import Solver \n",
    "from vpe.NeuralNet import NeuralN\n",
    "from vpe.VEModel import VE\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "\n",
    "print(tffloat(0.))\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "dirname = 'weightsModel-Test1/'\n",
    "# dirname = 'indptPrior-Test1/'\n",
    "\n",
    "os.makedirs(os.path.dirname(dirname), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create PDEState Object with Cheby Num terms (-1 for degree)'''\n",
    "omegaLength = 2.0\n",
    "numFElems   = 100\n",
    "numFENodes  = numFElems + 1\n",
    "xFE = tffloat( tf.linspace( 0., omegaLength, numFElems + 1) ) - 1.\n",
    "\n",
    "pdeState = PDE_State(xFE, dimK=4, dimF=1, dimU=8)\n",
    "'''Modify pdeState Bijcetor for kappa'''\n",
    "pdeState.kappaBij   = tfb.Chain( bijectors=[tfb.Shift(tffloat(1.)), tfb.Softplus()] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create solver Object'''\n",
    "\n",
    "solver = Solver( pdeState, xFE, isNonLinear=False )\n",
    "\n",
    "\n",
    "# '''Modify pdeState.stress-strain for nonlinear Youngs Modulus'''\n",
    "# import types\n",
    "# def stress_strain_nonLinear(self, index, kappa, u_trial):\n",
    "#     #print('custom stress-strain')\n",
    "#     dudx = ( u_trial[index] - u_trial[index+1]) / (self.pdeState.xFE[index] - self.pdeState.xFE[index+1])\n",
    "#     return (tf.keras.activations.sigmoid(tf.math.abs(dudx)) + kappa*5. ) /10.\n",
    "# solver.stress_strain = types.MethodType(stress_strain_nonLinear, solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VE( pdeState, solver )\n",
    "#model.dimU = numFENodes\n",
    "#model.logProbPhysResidual = model.physicsPenalty\n",
    "\n",
    "def createNNsPrior():\n",
    "    dimKFBlBr = model.dimK + model.dimF + model.dimBl + model.dimBr\n",
    "    nh = 50\n",
    "    U_KFBlBr  = NeuralN('U_of_KFBlBr', \n",
    "                    np.array([dimKFBlBr,\n",
    "                              nh, nh, nh, nh,\n",
    "                              model.dimU])\n",
    "                    )\n",
    "\n",
    "    k  = model.dimK\n",
    "    bl = k  + model.dimBl\n",
    "    br = bl + model.dimBr\n",
    "    Z_UF     = NeuralN('Z_of_UF',\n",
    "                    np.array([pdeState.dimU + model.dimF, \n",
    "                                nh, nh, nh, nh, \n",
    "                                model.dimK + model.dimBl + model.dimBr]),\n",
    "                    multOutputLayout = {'K': tf.range(0,k),\n",
    "                                        'Bl':tf.range(k,bl),'Br':tf.range(bl,br)}\n",
    "                    )\n",
    "\n",
    "    model.initPriorNetworks(U_KFBlBr=U_KFBlBr, Z_UF=Z_UF)\n",
    "    model.setModePrior()\n",
    "    return \n",
    "\n",
    "    \n",
    "USE_UNIFORM_PRIOR = False\n",
    "if USE_UNIFORM_PRIOR == True:\n",
    "    model.LatentKappaPrior   = tfp.distributions.Uniform(low=tffloat([-0.5]*pdeState.dimK), high=tffloat([0.5]*pdeState.dimK))#works\n",
    "    model.LatentForcingPrior = tfp.distributions.Uniform(low=tffloat([5.]*pdeState.dimF), high=tffloat([5.]*pdeState.dimF) )\n",
    "\n",
    "USE_NORMAL_PRIOR = True\n",
    "if USE_NORMAL_PRIOR == True:\n",
    "    model.LatentKappaPrior   = tfp.distributions.Uniform(low=tffloat([-1.]*pdeState.dimK), high=tffloat([1.]*pdeState.dimK) )\n",
    "    model.LatentForcingPrior = tfp.distributions.Uniform(low=tffloat([1.]*pdeState.dimF), high=tffloat([5.]*pdeState.dimF) )#works\n",
    "\n",
    "\n",
    "model.LatentBlPrior      = tfp.distributions.Uniform(low=tffloat([-0.5]), high=tffloat([0.5]))\n",
    "model.LatentBrPrior      = tfp.distributions.Uniform(low=tffloat([-0.5]), high=tffloat([0.5]) )\n",
    "\n",
    "\n",
    "print(model.LatentForcingPrior.sample())\n",
    "print(model.LatentBlPrior.sample())\n",
    "createNNsPrior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "def computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=True, SAVE=False):\n",
    "    \n",
    "    global totalTimeNNSolving\n",
    "    global totalTimeSolving  \n",
    "    \n",
    "    startSolving = time.time()\n",
    "    meanSamplesU, logVarSamplesU = model.priorModels['U_of_KFBlBr'].Map([samplesK, samplesF, samplesBcl, samplesBcr])\n",
    "    endSolving = time.time()\n",
    "    totalTimeNNSolving += endSolving - startSolving\n",
    "\n",
    "    us = model.reparameterize(meanSamplesU, logVarSamplesU )\n",
    "\n",
    "    residualsU = tf.constant(0., shape=[1])\n",
    "    residualsK = tf.constant(0., shape=[1])\n",
    "    residualsB = tf.constant(0., shape=[1])\n",
    "    \n",
    "    if PLOT == True:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, sharex=True,\n",
    "                                            figsize=(24, 4))\n",
    "    \n",
    "    for i in range(samplesK.shape[0]):\n",
    "\n",
    "        pdeState.kappa   = samplesK[i,:] \n",
    "        pdeState.forcing = samplesF[i,:] \n",
    "        pdeState.bdLeft  = samplesBcl[i,0] \n",
    "        pdeState.bdRight = samplesBcr[i,0] \n",
    "\n",
    "        startSolving = time.time()\n",
    "        u_true     = solver.solve_tf_linear(  )\n",
    "#         u_true     = solver.solve_tf_bfgs(  )\n",
    "#         u_trueSpec = solver.solve_tf_FESpectral_bfgs( )\n",
    "#         u_trueSpec = pdeState.u_funXFE( u_trueSpec[:,None] )\n",
    "        endSolving = time.time()\n",
    "        totalTimeSolving += endSolving - startSolving\n",
    "\n",
    "        meanU, diagVarU = pdeState.gaussChebyGaussCoeffs(meanSamplesU[i,:], tf.exp(logVarSamplesU[i,:]), xFE )\n",
    "        #meanU, diagVarU = meanSamplesU[i,:], tf.exp(logVarSamplesU[i,:])\n",
    "        std2U = 2.*tf.sqrt(diagVarU)\n",
    "        \n",
    "        startSolving = time.time()\n",
    "        uField = pdeState.u_funXFE(us[i,:][:,None])\n",
    "        #uField  = us[i,:]\n",
    "        endSolving = time.time()\n",
    "        totalTimeNNSolving += endSolving - startSolving\n",
    "\n",
    "        kappaField = pdeState.kappa_fun( xFE )\n",
    "\n",
    "        U_true_coeffs = pdeState.getChebyCoeffs_fromPoints(xFE, uField, model.dimU - 1)\n",
    "        #U_true_coeffs = uField\n",
    "        #print('U_true_coeffs = ', U_true_coeffs)\n",
    "\n",
    "\n",
    "        ZCoeffReconstMean, ZCoeffReconstlogvar = model.priorModels['Z_of_UF'].Map([ U_true_coeffs[None,:], samplesF[i,:][None,:]])\n",
    "        kappaCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstMean =  tf.reshape(kappaCoeffReconstMean,[-1])\n",
    "        kappaCoeffReconstVar  =  tf.exp(tf.reshape(kappaCoeffReconstlogVar,[-1]))\n",
    "        meanK, diagCovK = pdeState.gaussChebyGaussCoeffs(kappaCoeffReconstMean,kappaCoeffReconstVar, xFE)\n",
    "        meanKT, varKT = pdeState.unscentedGaussTransf(meanK, diagCovK, pdeState.kappaBij, k=2)\n",
    "        std2KT = 2*tf.sqrt(varKT)\n",
    "        print('std2KT = ', std2KT)\n",
    "\n",
    "        BlReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Bl'], axis=1)\n",
    "        BrReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        residualUi = ( tf.linalg.norm(  u_true - meanU ) / tf.linalg.norm( u_true ) )**2.\n",
    "        residualKi = ( tf.linalg.norm( kappaField - meanKT ) / tf.linalg.norm( kappaField ) )**2.\n",
    "        residualBi = ( tf.linalg.norm( ( BlReconst - samplesBcl[i,0] ) + ( samplesBcr[i,0] - BrReconst ) ) / tf.linalg.norm( samplesBcl[i,0] + samplesBcr[i,0] ) )**2.\n",
    "\n",
    "        residualsU = tf.concat([residualsU, residualUi[None]], 0)\n",
    "        residualsK = tf.concat([residualsK, residualKi[None]], 0)\n",
    "        residualsB = tf.concat([residualsB, residualBi[None]], 0)\n",
    "\n",
    "        \n",
    "        if PLOT == True:\n",
    "            #ax[0].plot( xFE, u_trueSpec, '--x', c='k', alpha = 0.1)\n",
    "            ax[0].plot( xFE , u_true)\n",
    "            ax[0].set_xlabel(r'$x$')\n",
    "            ax[0].set_ylabel(r'$u(x)$')\n",
    "            ax[0].set_title('FE Solver')\n",
    "            \n",
    "            ax[1].plot(xFE, meanU)\n",
    "            ax[1].fill_between(xFE, meanU + std2U, meanU - std2U, alpha=0.2)\n",
    "            ax[1].set_xlabel(r'$x$')\n",
    "            ax[1].set_ylabel(r'$u(x) \\pm 2\\sigma$')\n",
    "            ax[1].set_title('NN Solver')\n",
    "\n",
    "            ax[2].plot( xFE, kappaField)\n",
    "            ax[2].set_xlabel(r'$x$')\n",
    "            ax[2].set_ylabel(r'$\\kappa(x)$')\n",
    "            ax[2].set_title(r'True $\\kappa(x)$')\n",
    "            \n",
    "            ax[3].plot(xFE, meanKT)\n",
    "            ax[3].fill_between(xFE, meanKT + std2KT, meanKT- std2KT, alpha=0.2)\n",
    "            ax[3].set_xlabel(r'$x$')\n",
    "            ax[3].set_ylabel(r'$\\kappa(x) \\pm 2\\sigma$')\n",
    "            ax[3].set_title(r'Reconstructed $\\kappa(x)$')\n",
    "\n",
    "            ax[4].plot( xFE , tf.squeeze(pdeState.forcing_funXFE()))\n",
    "            ax[4].set_xlabel(r'$x$')\n",
    "            ax[4].set_ylabel(r'$f(x)$')\n",
    "            ax[4].set_title(r'Forcing')\n",
    "\n",
    "\n",
    "    if PLOT == True:\n",
    "        plt.tight_layout()\n",
    "        if SAVE == True:\n",
    "            plt.savefig('figs/OneDpoissonNONLinearInRangeSolves.pdf')\n",
    "        plt.show()\n",
    "\n",
    "    return residualsU, residualsK, residualsB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSample = 3\n",
    "PLOT = True\n",
    "sampleKGenerator = model.LatentKappaPrior\n",
    "samplesK   = sampleKGenerator.sample(sample_shape=(numSample))\n",
    "\n",
    "samplesF   = model.LatentForcingPrior.sample(sample_shape=(numSample))\n",
    "samplesBcl = model.LatentBlPrior.sample(sample_shape=(numSample))\n",
    "samplesBcr = model.LatentBrPrior.sample(sample_shape=(numSample))\n",
    "\n",
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "residualsU, residualsK, residualsB = computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=PLOT, SAVE=False)\n",
    "\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps =1e-2\n",
    "\n",
    "AllEpsU = []\n",
    "AllEpsK = []\n",
    "AllEpsB = []\n",
    "\n",
    "totalTimeTraining  = 0.\n",
    "\n",
    "trainModels      = False\n",
    "\n",
    "\n",
    "intervalELBOsave = 1000\n",
    "\n",
    "PLOT = True\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_prior(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = model.compute_nelbo_prior(iteration)\n",
    "    for priorvars in model.priorModels['trainable_variables']:\n",
    "        gradients    = tape.gradient(loss, priorvars)\n",
    "        gradients, globNorm = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        tf.debugging.check_numerics(gradients[0], \"GRAD NOT FINITE\")\n",
    "        #gradients = [tf.where(tf.is_nan(grad), tf.zeros_like(grad), grad) for grad in gradients]\n",
    "        optimizer.apply_gradients(zip(gradients, priorvars))\n",
    "    return loss\n",
    "\n",
    "if trainModels:\n",
    "       \n",
    "    '''Optimization sequence'''\n",
    "    model.n_sgd      = 1\n",
    "\n",
    "    num_iterations   = tfint(1_000_000)\n",
    "\n",
    "    model.epsilon_r.assign( tffloat(eps) )\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        1e-3, int(num_iterations/5), 0.5, staircase=True, name=None\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam( lr )\n",
    "\n",
    "    elboAll     = []\n",
    "    startTraining = time.time()\n",
    "    for epoch in tf.range(0, num_iterations ):\n",
    "\n",
    "        start_time = time.time()\n",
    "        loss = train_step_prior(optimizer, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % intervalELBOsave == 0:\n",
    "            #tf.print('epsi_r = ', model.epsilon_r)\n",
    "            elboAll.append(-loss)\n",
    "            print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "                .format(epoch, -loss, end_time - start_time))\n",
    "\n",
    "    endTraining = time.time()\n",
    "    totalTimeTraining += endTraining - startTraining\n",
    "    print(\"DONE TRAINING FOR EPSI\", eps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If you want to load Model Weights'''\n",
    "saveModelWeights = False\n",
    "loadModelWeights = True\n",
    "if saveModelWeights:\n",
    "    print('MODEL WEIGHTS SAVED')\n",
    "    \n",
    "    os.makedirs(os.path.dirname(dirname), exist_ok=True)\n",
    "    model.priorModels['U_of_KFBlBr'].NN.save_weights(dirname+'U_of_KFBlBr_weights.h5')\n",
    "    model.priorModels['Z_of_UF'].NN.save_weights(dirname+'Z_of_UF_weights.h5')\n",
    "    \n",
    "    model.priorModels['U_of_KFBlBr'].NN.compile() \n",
    "    model.priorModels['Z_of_UF'].NN.compile()\n",
    "    model.priorModels['U_of_KFBlBr'].NN.save(dirname+'U_of_KFBlBr_weights.model')\n",
    "    model.priorModels['Z_of_UF'].NN.save(dirname+'Z_of_UF_weights.model')\n",
    "\n",
    "if loadModelWeights:\n",
    "    print('LOADED WEIGHTS SAVED')\n",
    "\n",
    "    model.priorModels['U_of_KFBlBr'].NN = tf.keras.models.load_model(dirname+'U_of_KFBlBr_weights.model')\n",
    "    model.priorModels['Z_of_UF'].NN = tf.keras.models.load_model(dirname+'Z_of_UF_weights.model')\n",
    "\n",
    "    model.priorModels['U_of_KFBlBr'].NN.compile()\n",
    "    model.priorModels['Z_of_UF'].NN.compile()\n",
    "    # Check its architecture\n",
    "    model.priorModels['U_of_KFBlBr'].NN.summary()\n",
    "    model.priorModels['Z_of_UF'].NN.summary()\n",
    "\n",
    "\n",
    "#print(elboAll)\n",
    "if trainModels:\n",
    "    elboAll =  np.array(elboAll)\n",
    "    np.savetxt('ELBOValsModel', elboAll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'totalTimeTraining = ', totalTimeTraining)\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSample  = 5\n",
    "samplesK   = model.LatentKappaPrior.sample(sample_shape=(numSample))\n",
    "samplesF   = model.LatentForcingPrior.sample(sample_shape=(numSample))\n",
    "samplesBcl = model.LatentBlPrior.sample(sample_shape=(numSample))\n",
    "samplesBcr = model.LatentBrPrior.sample(sample_shape=(numSample))\n",
    "\n",
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "residualsU, residualsK, residualsB = computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=PLOT, SAVE=False)\n",
    "\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(elboAll.shape[0]),  elboAll )\n",
    "scale = 1e3\n",
    "plt.ylim(-scale,scale)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Times.txt', 'w') as the_file:\n",
    "    the_file.write('totalTimeTraining = '  + str(totalTimeTraining) + 's'+ '\\n' )\n",
    "    the_file.write('totalTimeSolving = '  + str(totalTimeSolving) + 's'+  '\\n' )\n",
    "    the_file.write('totalTimeNNSolving = ' + str(totalTimeNNSolving) + 's'+  '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.numEachSide = 40\n",
    "dataYEpsi = tffloat(0.010)\n",
    "tfNan     = tf.constant(np.nan)\n",
    "\n",
    "# def observationMap( u, x ):\n",
    "#     u = tf.reshape(u, [-1])\n",
    "#     x = tf.reshape(x, [-1])\n",
    "#     return tf.sin( x * 20.) * u     , x\n",
    "#     return tf.sin( x * 20 ) / 20 + u, x\n",
    "#     return u, x\n",
    "\n",
    "def observationMap(u, x):\n",
    "\n",
    "    u = tf.reshape(u, [-1])\n",
    "    x = tf.reshape(x, [-1])\n",
    "\n",
    "    x = tf.concat([x[:model.numEachSide],\n",
    "        x[-model.numEachSide:]], 0)\n",
    "\n",
    "    u = tf.concat([u[:model.numEachSide],\n",
    "        u[-model.numEachSide:]], 0)\n",
    "\n",
    "    return u, x \n",
    "\n",
    "def addIndtNoise(u):\n",
    "    return u + tf.random.normal(stddev=dataYEpsi, shape=u.shape, dtype=floatf)\n",
    "\n",
    "def plotTrueSlnSamples(samplesK, samplesF, samplesBcl, samplesBcr):\n",
    "    \n",
    "    fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=4, sharex=False,\n",
    "                                        figsize=(20, 3))\n",
    "    \n",
    "    u_All = tf.constant(0., shape=[1,  int(2*model.numEachSide)], dtype=floatf)\n",
    "#     u_All = tf.constant(0., shape=[1,  101], dtype=floatf)\n",
    "\n",
    "    #uInit = solver.solve_tf(  )\n",
    "    #A, f  = solver.assemble_tf( uInit )\n",
    "    #precond = tf.linalg.inv(A)\n",
    "\n",
    "    for i in range(samplesK.shape[0]):\n",
    "        \n",
    "        model.pdeState.forcing = tf.reshape(samplesF[i,:], [-1]) \n",
    "        model.pdeState.kappa   = tf.reshape(samplesK[i,:], [-1]) \n",
    "        model.pdeState.bdLeft  = tf.reshape(samplesBcl[i,:], []) \n",
    "        model.pdeState.bdRight = tf.reshape(samplesBcr[i,:], []) \n",
    "\n",
    "#         u_true       = solver.solve_tf_bfgs(  )\n",
    "        u_true       = solver.solve_tf_linear( )\n",
    "        # print('u_true.shape = ', u_true.shape)\n",
    "        u_obs, x_obs = observationMap(u_true, xFE)\n",
    "        # print('u_obs.shape = ', u_obs.shape)\n",
    "        u_obs_noise  = addIndtNoise(u_obs)\n",
    "        # print('u_obs_noise.shape = ', u_obs_noise.shape)\n",
    "        u_obs_noise_dropNan = u_obs_noise # tf.gather_nd(u_obs_noise, tf.where(tf.math.is_finite(u_obs_noise)))\n",
    "#         u_obs_noise_dropNan = tf.gather_nd(u_obs_noise, tf.where(tf.math.is_finite(u_obs_noise)))\n",
    "        # print('u_obs_noise_dropNan.shape = ', u_obs_noise_dropNan.shape)\n",
    "        u_All = tf.concat([u_All,u_obs_noise_dropNan[None, :] ], 0)\n",
    "\n",
    "#         x_obsp = x_obs # tf.concat([x_obs[:model.numEachSide], tf.constant([np.nan]),x_obs[-model.numEachSide:]], 0)\n",
    "#         u_obsp = u_obs # tf.concat([u_obs[:model.numEachSide], tf.constant([np.nan]),u_obs[-model.numEachSide:]], 0)\n",
    "#         u_obs_noisep = u_obs_noise # tf.concat([u_obs_noise[:model.numEachSide], tf.constant([np.nan]),u_obs_noise[-model.numEachSide:]], 0)\n",
    "        x_obsp = tf.concat([x_obs[:model.numEachSide], tf.constant([np.nan]),x_obs[-model.numEachSide:]], 0)    \n",
    "        u_obsp =  tf.concat([u_obs[:model.numEachSide], tf.constant([np.nan]),u_obs[-model.numEachSide:]], 0)\n",
    "        u_obs_noisep =  tf.concat([u_obs_noise[:model.numEachSide], tf.constant([np.nan]),u_obs_noise[-model.numEachSide:]], 0)\n",
    "\n",
    "        \n",
    "        ax0.plot(x_obsp, u_obsp)\n",
    "        # ax0.set_title('u_mapped')\n",
    "        ax1.plot(x_obsp,u_obs_noisep)\n",
    "        # ax1.set_title('u_mappedNoise')\n",
    "        ax2.plot(tf.range(u_true.shape[0]), u_true)\n",
    "        # ax2.set_title('u')\n",
    "\n",
    "        kappaField = pdeState.kappa_fun(xFE)\n",
    "        ax3.plot( xFE, kappaField )\n",
    "        # ax3.set_title('kappa field')\n",
    "    fig.canvas.draw()\n",
    "    extent = ax0.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('u_obs.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax1.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('u_obsNoise.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax2.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('u_true.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax3.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('TrueKappa.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    plt.show()\n",
    "    u_All = u_All[1:,:]\n",
    "    return u_All\n",
    "\n",
    "model.dimY = pdeState.xFE.shape[0]\n",
    "\n",
    "numData = 100\n",
    "print('model.dimK = ', model.dimK)\n",
    "samplesKdata   = model.LatentKappaPrior.sample(sample_shape=(numData))\n",
    "samplesFdata   = model.LatentForcingPrior.sample(sample_shape=(numData))\n",
    "samplesBldata  = model.LatentBlPrior.sample(sample_shape=(numData))\n",
    "samplesBrdata  = model.LatentBrPrior.sample(sample_shape=(numData))\n",
    "\n",
    "\n",
    "priorFEpsi = tf.constant(1e-3,dtype=floatf)\n",
    "priorMeanF = samplesFdata #+ tf.random.normal(stddev=priorFEpsi,  shape=samplesFdata.shape, dtype=floatf)\n",
    "# priorMeanF = samplesFdata * 0  + 2.5\n",
    "priorFEpsi = tffloat(1.)\n",
    "priorStdF  = tf.tile(priorFEpsi[None,None], priorMeanF.shape)\n",
    "model.dataForcingPrior = (priorMeanF, tf.math.log(priorStdF)*2 )\n",
    "\n",
    "variableSTD = tffloat(1e-1)\n",
    "\n",
    "priorKEpsi = variableSTD\n",
    "priorMeanK = samplesKdata #+ tf.random.normal(stddev=priorKEpsi,  shape=samplesKdata.shape, dtype=floatf)\n",
    "# priorMeanK = samplesKdata * 0 \n",
    "priorKEpsi = tffloat(0.5)\n",
    "priorStdK  = tf.tile(priorKEpsi[None,None], priorMeanK.shape)\n",
    "model.dataKappaPrior = (priorMeanK,  tf.math.log(priorStdK)*2)\n",
    "\n",
    "priorBlEpsi = variableSTD\n",
    "priorMeanBl = samplesBldata #+ tf.random.normal(stddev=priorBlEpsi,  shape=samplesBldata.shape, dtype=floatf)\n",
    "# priorMeanBl = priorMeanBl * 0 \n",
    "priorBlEpsi = tffloat(0.5)\n",
    "priorStdBl  = tf.tile(priorBlEpsi[None,None], priorMeanBl.shape)\n",
    "model.dataBlPrior = (priorMeanBl,  tf.math.log(priorStdBl)*2)\n",
    "\n",
    "priorBrEpsi = variableSTD\n",
    "priorMeanBr = samplesBrdata #+ tf.random.normal(stddev=priorBrEpsi,  shape=samplesBrdata.shape, dtype=floatf)\n",
    "# priorMeanBr = priorMeanBr * 0 \n",
    "priorBrEpsi = tffloat(0.5)\n",
    "priorStdBr  = tf.tile(priorBrEpsi[None,None], priorMeanBr.shape)\n",
    "model.dataBrPrior = (priorMeanBr,  tf.math.log(priorStdBr)*2)\n",
    "\n",
    "model.dataY = plotTrueSlnSamples(samplesKdata, samplesFdata, samplesBldata, samplesBrdata)\n",
    "print(model.dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"{}ModelDataset\".format(dirname), model.dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.dataForcingPrior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dimY = int( model.numEachSide * 2 )\n",
    "# model.dimY = 101\n",
    "\n",
    "\n",
    "def createNNsPost():\n",
    "   \n",
    "    nh = 100\n",
    "    U_Y = NeuralN('U_of_Y',\n",
    "                    np.array([model.dimY,\n",
    "                      nh, nh, \n",
    "                      model.dimU]))\n",
    "\n",
    "    model.U_Y      = U_Y\n",
    "    model.U_Y.compile()\n",
    "\n",
    "    model.varListPostNets = [ \n",
    "                               model.U_Y.trainable_variables\n",
    "                            ]\n",
    "    \n",
    "    model.postModels = {\n",
    "                         model.U_Y.NN_name:model.U_Y,\n",
    "                         'trainable_variables':model.varListPostNets\n",
    "                        }\n",
    "\n",
    "    return \n",
    "\n",
    "createNNsPost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nelbo_post(self, iteration):\n",
    "\n",
    "    nelboSGD = 0.\n",
    "    i = iteration % self.dataY.shape[0] \n",
    "\n",
    "    f_i  =  self.dataForcingPrior[0][i,:][None, :]\n",
    "    print('f_i = ', f_i)\n",
    "\n",
    "    mean_phi, logvar_phi = self.postModels['U_of_Y'].Map( [self.dataY[i,:][None,:]] )\n",
    "    us                   = self.reparameterize( mean_phi, logvar_phi )\n",
    "    logq_phi_u_y         = self.log_normal_pdf( us, mean_phi, logvar_phi )\n",
    "\n",
    "    uFE      = tf.reshape(self.pdeState.u_funXFE(tf.reshape(us, [-1,1])) , [1,-1] )\n",
    "\n",
    "    g_u, x   = observationMap( uFE, pdeState.xFE )\n",
    "\n",
    "    logP_y_u = self.log_normal_pdf(self.dataY[i,:][None,:], g_u[None,:], 2.*tf.math.log(self.epsilon_y) )\n",
    "\n",
    "    elbo      = tf.reduce_mean(  logP_y_u  - logq_phi_u_y   )\n",
    "\n",
    "    nelboSGD -= elbo\n",
    "\n",
    "    return nelboSGD  \n",
    "\n",
    "import types\n",
    "model.compute_nelbo_post = types.MethodType(compute_nelbo_post, model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "totalTimeTrainingPost  = 0.\n",
    "\n",
    "trainModels      = True\n",
    "\n",
    "\n",
    "intervalELBOsave = 1000\n",
    "\n",
    "PLOT = True\n",
    "\n",
    "model.epsilon_y.assign(tffloat(0.01)) #res1\n",
    "# model.epsilon_r.assign(tffloat(0.1))\n",
    "# model.epsilon_y.assign(dataYEpsi)\n",
    "\n",
    "# model.setModePost()\n",
    "# model.postModels['trainable_variables'] = [model.postModels['KBlBr_of_YF'].trainable_variables]\n",
    "\n",
    "# model.setModeCouple()\n",
    "\n",
    "loss = model.compute_nelbo_post(0)\n",
    "@tf.function\n",
    "def train_step_post(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = model.compute_nelbo_post(iteration)\n",
    "        print('loss  = ', loss)\n",
    "\n",
    "    for postVars in [ model.postModels['U_of_Y'].trainable_variables ]:\n",
    "        gradients = tape.gradient(loss, postVars)\n",
    "        optimizer.apply_gradients(zip(gradients, postVars))\n",
    "    \n",
    "#     for priorVars in [model.priorModels['Z_of_UF'].trainable_variables]:\n",
    "#         gradients = tape.gradient(loss, priorVars)\n",
    "#         optimizer.apply_gradients(zip(gradients, priorVars))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "if trainModels:\n",
    "    \n",
    "    createNNsPost()\n",
    "    \n",
    "    '''Optimization sequence'''\n",
    "    model.n_sgd      = 1\n",
    "\n",
    "    num_iterations   = tfint(500_000)\n",
    "\n",
    "    # model.epsilon_r.assign( tffloat(eps) )\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        1e-4, int(num_iterations/10), 0.5, staircase=True, name=None\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam( lr )\n",
    "    # optimizer = tf.keras.optimizers.Adam( 1e-3 )\n",
    "\n",
    "\n",
    "    elboAll       = []\n",
    "    startTraining = time.time()\n",
    "    for epoch in tf.range(0, num_iterations ):\n",
    "\n",
    "        start_time = time.time()\n",
    "        loss = train_step_post(optimizer, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % intervalELBOsave == 0:\n",
    "            #tf.print('epsi_r = ', model.epsilon_r)\n",
    "            elboAll.append(-loss)\n",
    "            print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "                .format(epoch, -loss, end_time - start_time))\n",
    "\n",
    "    endTraining = time.time()\n",
    "    totalTimeTraining += endTraining - startTraining\n",
    "    print(\"DONE TRAINING FOR EPSI\", eps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elboNP = np.array(elboAll)\n",
    "plt.plot(range(elboNP.shape[0]), elboAll)\n",
    "# plt.ylim(-1e6,1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelWeights = False\n",
    "loadModelWeights = True\n",
    "'''If you want to load Model Weights'''\n",
    "\n",
    "if loadModelWeights:\n",
    "#     model.postModels['KBlBr_of_Y'].NN.load_weights(dirname+'/KBlBr_of_Y_weights.h5')\n",
    "    model.postModels['U_of_Y'].NN.load_weights(dirname+'/U_of_Y_weights.h5')\n",
    "\n",
    "#     model.postModels['KBlBr_of_Y'].NN.compile()\n",
    "    model.postModels['U_of_Y'].NN.compile()\n",
    "    # Check its architecture\n",
    "#     model.postModels['KBlBr_of_Y'].NN.summary()\n",
    "    model.postModels['U_of_Y'].NN.summary()\n",
    "    print(\"LOADED WEIGHTS\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if saveModelWeights:\n",
    "    # dirname = 'weightsModel-100/'.format(eps)\n",
    "    # os.makedirs(os.path.dirname(dirname), exist_ok=True)\n",
    "    model.postModels['U_of_Y'].NN.compile()\n",
    "\n",
    "    model.postModels['U_of_Y'].NN.save(dirname+'/U_of_Y_weights.model')\n",
    "    model.postModels['U_of_Y'].NN.save_weights(dirname+'/U_of_Y_weights.h5')\n",
    "    print(\"SAVED WEIGHTS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(elboAll)\n",
    "if trainModels:\n",
    "    elboAll =  np.array(elboAll)\n",
    "    np.savetxt('ELBOValsModel-{}epsi'.format(eps), elboAll)\n",
    "\n",
    "#plt.plot(range(elboAll.shape[0]),  elboAll )\n",
    "#scale = 1e3\n",
    "#plt.ylim(-scale,scale)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "print( 'totalTimeTraining = ', totalTimeTraining)\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)\n",
    "\n",
    "with open('TimesRecording.dat', 'w') as file:\n",
    "    np.savetxt(file, totalTimeTraining)\n",
    "    np.savetxt(file, totalTimeSolving)\n",
    "    np.savetxt(file, totalTimeSolving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataYEpsi =tffloat(0.010)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "dirname = '100datasetmissingObsTest2/'\n",
    "os.makedirs(os.path.dirname(dirname), exist_ok=True)\n",
    "\n",
    "\n",
    "def addIndtNoise(u):\n",
    "    return u + tf.random.normal(stddev=dataYEpsi, shape=u.shape, dtype=floatf)\n",
    "\n",
    "def plotTrueSlnSamplesPost(samplesK, samplesF, samplesBcl, samplesBcr, SAVE=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                                        figsize=(20, 8))\n",
    "    \n",
    "    u_All = tf.constant(0., shape=[1, model.dimY ], dtype=floatf)\n",
    "    color = pyplot.cm.turbo(np.linspace(0, 1,samplesK.shape[0]))\n",
    "    color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf']\n",
    "    for i in range(samplesK.shape[0]):\n",
    "        \n",
    "        model.pdeState.forcing =  tf.reshape(samplesF[i,:], [-1]) \n",
    "        model.pdeState.kappa   =  tf.reshape(samplesK[i,:], [-1]) \n",
    "        model.pdeState.bdLeft  =  tf.reshape(samplesBcl[i,:], []) \n",
    "        model.pdeState.bdRight =  tf.reshape(samplesBcr[i,:], []) \n",
    "\n",
    "#         u_prior   = solver.solve_tf_bfgs( )\n",
    "        u_prior   = solver.solve_tf_linear(  )\n",
    "        u_g, x_g  = observationMap(u_prior, xFE)\n",
    "        u_gp      = u_g # tf.concat([u_g[:model.numEachSide], tf.constant([np.nan]) ,u_g[-model.numEachSide:]], 0)\n",
    "#         x_gp      = x_g # tf.concat([x_g[:model.numEachSide], tf.constant([np.nan]) ,x_g[-model.numEachSide:]], 0)\n",
    "        x_gp      = tf.concat([x_g[:model.numEachSide], tf.constant([np.nan]) ,x_g[-model.numEachSide:]], 0)\n",
    "\n",
    "        u_gNoise  = addIndtNoise(u_g)\n",
    "#         u_gNoisep = u_gNoise # tf.concat([u_gNoise[:model.numEachSide], tf.constant([np.nan]) ,u_gNoise[-model.numEachSide:]], 0)\n",
    "        u_gNoisep = tf.concat([u_gNoise[:model.numEachSide], tf.constant([np.nan]) ,u_gNoise[-model.numEachSide:]], 0)\n",
    "\n",
    "        #         u_gNoisep = tf.concat([u_gNoise[:model.numEachSide], tf.constant([np.nan]) ,u_gNoise[-model.numEachSide:]], 0)\n",
    "#         u_gNoise = tf.gather_nd(u_gNoise, tf.where(tf.math.is_finite(u_gNoise)))\n",
    "        u_All = tf.concat([u_All, u_gNoise[None,:] ], 0)\n",
    "\n",
    "        ax[0,0].plot(x_gp,u_gNoisep, c=color[i])\n",
    "        # ax[0,0].set_title(r'$y$')\n",
    "\n",
    "        ax[0,1].plot(pdeState.xFE, u_prior, c=color[i])\n",
    "        # ax[0,1].set_title(r'True $u(x)$')\n",
    "        \n",
    "        #ax[0,2].plot(pdeState.xFE, u_missPhys - u_prior,'--' ,c='k', alpha=0.5)\n",
    "        # ax[0,2].plot(x_g, u_missPhysNoise - u_prior)\n",
    "        # ax[0,2].set_ylim(-0.25, 0.25)\n",
    "        # ax[0,2].set_title(r'True $\\rho(u, x)$')\n",
    "\n",
    "        kappaField = pdeState.kappa_fun(xFE)\n",
    "        ax[0,3].plot( pdeState.xFE, kappaField, c=color[i])\n",
    "        # ax[0,3].set_title(r'True $\\kappa(x)$')\n",
    "\n",
    "        meanU_phi, logvar_phi = model.postModels['U_of_Y'].Map([u_gNoise[None,:]])\n",
    "        us                    = model.reparameterize( meanU_phi, logvar_phi ) \n",
    "        meanU, diagVarU = pdeState.gaussChebyGaussCoeffs(meanU_phi[0,:], tf.exp(logvar_phi[0,:]), xFE )\n",
    "        std2U = 2.*tf.sqrt(diagVarU)\n",
    "#         print('std2U = \\n', std2U)\n",
    "\n",
    "        ax[1,0].plot(pdeState.xFE, meanU, alpha=1., c=color[i])\n",
    "        ax[1,0].fill_between(pdeState.xFE, meanU - std2U, meanU + std2U, alpha=0.1, color=color[i])\n",
    "        \n",
    "        ZCoeffReconstMean, ZCoeffReconstlogvar = model.priorModels['Z_of_UF'].Map([ meanU_phi, samplesF[i,:][None,:]])\n",
    "\n",
    "        kappaCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "\n",
    "        BLCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Bl'], axis=1)\n",
    "        BLCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['Bl'], axis=1)\n",
    "\n",
    "        BRCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Br'], axis=1)\n",
    "        BRCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        kappaCoeffReconstMean =  tf.reshape(kappaCoeffReconstMean,[-1])\n",
    "        kappaCoeffReconstVar  =  tf.exp(tf.reshape(kappaCoeffReconstlogVar,[-1]))\n",
    "        meanK, diagCovK = pdeState.gaussChebyGaussCoeffs(kappaCoeffReconstMean,kappaCoeffReconstVar, xFE)\n",
    "        meanKT, varKT = pdeState.unscentedGaussTransf(meanK, diagCovK, pdeState.kappaBij, k=1)\n",
    "        std2KT = 2*tf.sqrt(varKT)\n",
    "\n",
    "        BlReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Bl'], axis=1)\n",
    "        BrReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        ax[1,3].plot(pdeState.xFE, meanKT, c=color[i])\n",
    "        ax[1,3].fill_between(pdeState.xFE, meanKT - std2KT, meanKT + std2KT, alpha=0.2, color=color[i])\n",
    "        # ax[1,3].set_title(r'Reconstructed $\\kappa(x)$')  \n",
    "\n",
    " \n",
    "    plt.tight_layout()\n",
    "    if SAVE is not None:\n",
    "        plt.tight_layout()\n",
    "        extent = ax[0, 0].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}Datay.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 1].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}TrueSol.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 2].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}TrueRho.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 3].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}TrueKappa.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 0].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}Reconstructedy.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 1].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}ReconstructedSol.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 2].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}ReconstructedRho.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 3].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('{}ReconstructedKappa.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig('MissingPhysFig{}.pdf'.format(SAVE))\n",
    "    plt.show()\n",
    "\n",
    "    u_All = u_All[1:,:]\n",
    "    return u_All\n",
    "\n",
    "\n",
    "#model.dataY = plotTrueSlnSamplesPost(samplesKdata, samplesFdata, samplesBldata, samplesBrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numData = 5\n",
    "solver = Solver( pdeState, xFE, isNonLinear=False )\n",
    "\n",
    "samplesKdataPost   = model.LatentKappaPrior.sample(sample_shape=(numData))\n",
    "# samplesFdataPost   = model.LatentForcingPrior.sample(sample_shape=(numData))\n",
    "samplesFdataPost   = tf.reshape(tf.linspace(2., 5., 5), [-1, 1])\n",
    "samplesBldataPost  = model.LatentBlPrior.sample(sample_shape=(numData))\n",
    "samplesBrdataPost  = model.LatentBrPrior.sample(sample_shape=(numData))\n",
    "\n",
    "# samplesKdataPost  = samplesKdata  [0:5,:]\n",
    "# samplesFdataPost  = samplesFdata  [0:5,:]\n",
    "# samplesBldataPost = samplesBldata [0:5,:]\n",
    "# samplesBrdataPost = samplesBrdata [0:5,:]               \n",
    "\n",
    "plotTrueSlnSamplesPost(samplesKdataPost, samplesFdataPost, samplesBldataPost, samplesBrdataPost, SAVE='indptPrior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTestSamples = 100\n",
    "\n",
    "samplesKdataTest  = model.LatentKappaPrior.sample(sample_shape=(numTestSamples))\n",
    "samplesFdataTest  = model.LatentForcingPrior.sample(sample_shape=(numTestSamples))\n",
    "# samplesFdataTest  = tf.reshape(tf.linspace(2., 5., numTestSamples), [-1, 1])\n",
    "samplesBldataTest  = model.LatentBlPrior.sample(sample_shape=(numTestSamples))\n",
    "samplesBrdataTest  = model.LatentBrPrior.sample(sample_shape=(numTestSamples))\n",
    "\n",
    "NSE_u = 0.\n",
    "NSE_k = 0.\n",
    "\n",
    "for i in range (numTestSamples):\n",
    "\n",
    "        model.pdeState.forcing =  tf.reshape(samplesFdataTest[i,:], [-1]) \n",
    "        model.pdeState.kappa   =  tf.reshape(samplesKdataTest[i,:], [-1]) \n",
    "        model.pdeState.bdLeft  =  tf.reshape(samplesBldataTest[i,:], []) \n",
    "        model.pdeState.bdRight =  tf.reshape(samplesBrdataTest[i,:], []) \n",
    "\n",
    "#         u_prior   = solver.solve_tf_bfgs( )\n",
    "        u_prior   = solver.solve_tf_linear(  )\n",
    "        u_g, x_g  = observationMap(u_prior, xFE)\n",
    "        u_gp      = u_g # tf.concat([u_g[:model.numEachSide], tf.constant([np.nan]) ,u_g[-model.numEachSide:]], 0)\n",
    "\n",
    "        u_gNoise  = addIndtNoise(u_g)\n",
    "\n",
    "        kappaField = pdeState.kappa_fun(xFE)\n",
    "\n",
    "        meanU_phi, logvar_phi = model.postModels['U_of_Y'].Map([u_gNoise[None,:]])\n",
    "        us                    = model.reparameterize( meanU_phi, logvar_phi ) \n",
    "        meanU, diagVarU = pdeState.gaussChebyGaussCoeffs(meanU_phi[0,:], tf.exp(logvar_phi[0,:]), xFE )\n",
    "        std2U = 2.*tf.sqrt(diagVarU)\n",
    "\n",
    "        NSE_u += tf.linalg.norm(u_prior - meanU)**2/tf.linalg.norm(u_prior)**2\n",
    "        numWithinU = tf.reduce_sum(tf.where(tf.math.logical_and(u_prior > meanU-std2U, u_prior < meanU+std2U), 1, 0))\n",
    "        \n",
    "        ZCoeffReconstMean, ZCoeffReconstlogvar = model.priorModels['Z_of_UF'].Map([ meanU_phi, samplesFdataTest[i,:][None,:]])\n",
    "\n",
    "        kappaCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "\n",
    "        kappaCoeffReconstMean =  tf.reshape(kappaCoeffReconstMean,[-1])\n",
    "        kappaCoeffReconstVar  =  tf.exp(tf.reshape(kappaCoeffReconstlogVar,[-1]))\n",
    "        meanK, diagCovK = pdeState.gaussChebyGaussCoeffs(kappaCoeffReconstMean,kappaCoeffReconstVar, xFE)\n",
    "        meanKT, varKT = pdeState.unscentedGaussTransf(meanK, diagCovK, pdeState.kappaBij, k=1)\n",
    "        std2KT = 2*tf.sqrt(varKT)\n",
    "\n",
    "        NSE_k += tf.linalg.norm( meanKT - kappaField ) ** 2. /  tf.linalg.norm(meanKT) ** 2.\n",
    "        numWithinK = tf.reduce_sum(tf.where(tf.math.logical_and(kappaField > meanKT-std2KT, kappaField < meanKT+std2KT), 1, 0))\n",
    "\n",
    "MNSE_u = NSE_u / numTestSamples\n",
    "MNSE_k = NSE_k / numTestSamples\n",
    "\n",
    "fracWithinU = numWithinU/ (numTestSamples*u_prior.shape[0])\n",
    "fracWithinK = numWithinK/ (numTestSamples*kappaField.shape[0])\n",
    "\n",
    "print('MNSE_u = ', MNSE_u)\n",
    "print('MNSE_k = ', MNSE_k)\n",
    "\n",
    "print('fracWithinU = ', fracWithinU)\n",
    "print('fracWithinK = ', fracWithinK)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f27e755c6e9f953092984d2fa7d5cd43e84a5cfdd14fc533980b318a0988c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
