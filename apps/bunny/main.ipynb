{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwd = %pwd\n",
    "%cd '/path to FEM auxiliary input scipt dir/'\n",
    "pwd = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(14)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(14)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=13000)])\n",
    "\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "except:\n",
    "  # Invalid device or cannot modify logical devices once initialized.\n",
    "  pass\n",
    "\n",
    "import time\n",
    "\n",
    "from pddlvm.utilities import tf, tfp, np, plt, tfb, floatf, tffloat, tfint, updateTfFloat,  _0\n",
    "updateTfFloat ( tf.float32 )\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "from pddlvm.poisson1DPDEState import PDE_State\n",
    "from pddlvm.poisson1DSolver import Solver \n",
    "from pddlvm.NeuralNet import NeuralN\n",
    "from VEModelBunny import VE\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "print(tffloat(0.))\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "prefix  = 'mirrorArch'\n",
    "dirname = '{}/'.format(prefix)\n",
    "os.makedirs(os.path.dirname(dirname), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bunny\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "\n",
    "print('Istanciated')\n",
    "FEBunny.initialize( 0 )\n",
    "print('Initialized')\n",
    "\n",
    "MeshNodes = tffloat(FEBunny.getNodeCoords())\n",
    "\n",
    "coeffs = tf.reshape(tf.constant([ 1. ]), [-1,1])\n",
    "FEBunny.setKappaCoeffs( coeffs )\n",
    "\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "\n",
    "A = convert_sparse_matrix_to_sparse_tensor(A)\n",
    "print(type(A))\n",
    "\n",
    "_ = FEBunny.AssembleAndSolve()\n",
    "\n",
    "ForcingVect = tffloat( FEBunny.getForcingVect( ) )\n",
    "ForcingVect = tf.reshape( ForcingVect, [-1,1] )\n",
    "\n",
    "normForcingVect = tf.linalg.norm(ForcingVect)\n",
    "A = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maxi = tf.reduce_max(MeshNodes, axis = 0) + 10.\n",
    "mini = tf.reduce_min(MeshNodes, axis = 0) - 10.\n",
    "a   = tffloat([-1., -1., -1.]) \n",
    "b   = tffloat([ 1.,  1.,  1.]) \n",
    "\n",
    "def toByUnitCube(MeshNodes):\n",
    "    return (b-a) * (MeshNodes - mini) / (maxi - mini) + a\n",
    "    \n",
    "def fromByUnitCube(cubeNodes):\n",
    "    return (maxi - mini) * (cubeNodes - a) /(b - a) + mini\n",
    "\n",
    "def fromByUnitYLine( col ):\n",
    "    maxY = tf.reduce_max( MeshNodes[:,col] )\n",
    "    minY = tf.reduce_min( MeshNodes[:,col] )\n",
    "    a, b = -1., 1.\n",
    "    return (b-a) * (MeshNodes[:,col] - minY) / (maxY - minY) + a\n",
    "\n",
    "def chebyTrig(x, n):\n",
    "    return tf.math.cos(n * tf.math.acos(x))\n",
    "\n",
    "def VolumeChebyMesh(MeshCoords, numN):\n",
    "    N = tf.range(0, numN, dtype=floatf)\n",
    "    def bind(N): return chebyTrig(MeshCoords, N)\n",
    "    T3DMesh = tf.vectorized_map(bind, N)\n",
    "    return T3DMesh\n",
    "\n",
    "numN = 7\n",
    "\n",
    "uCubeNodes = toByUnitCube(MeshNodes)\n",
    "T3DMesh = VolumeChebyMesh(uCubeNodes, numN)\n",
    "\n",
    "def chebyToFE(uc):\n",
    "    return tf.einsum('nmli,nk,mk,lk->ki', uc, T3DMesh[:,:,0] , T3DMesh[:,:,1], T3DMesh[:,:,2])\n",
    "\n",
    "def chebyToFE_diagCov(uc):\n",
    "    return tf.einsum('nk,mk,lk,nmli,nk,mk,lk->ki',\n",
    "                      T3DMesh[:,:,0] , T3DMesh[:,:,1], T3DMesh[:,:,2],\n",
    "                      uc,\n",
    "                      T3DMesh[:,:,0] , T3DMesh[:,:,1], T3DMesh[:,:,2]\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposalU = tf.random.uniform(minval=0., maxval=0.1, shape=[numN,numN,numN,3], dtype=floatf)\n",
    "print(proposalU)\n",
    "dispField = chebyToFE(proposalU)\n",
    "print(dispField)\n",
    "# raise\n",
    "print(uCubeNodes[:,0])\n",
    "print(dispField)\n",
    "#%matplotlib widget\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "angle = 0\n",
    "rot   = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "img = ax.scatter(uCubeNodes[:,0], uCubeNodes[:,2], uCubeNodes[:,1], c=dispField[:,0], cmap=plt.hot(), alpha=0.5)\n",
    "plt.colorbar( img )\n",
    "ax.view_init(angle, rot)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "img = ax.scatter(uCubeNodes[:,0], uCubeNodes[:,2], uCubeNodes[:,1], c=dispField[:,1], cmap=plt.hot(), alpha=0.5)\n",
    "plt.colorbar( img )\n",
    "ax.view_init(angle, rot)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "img = ax.scatter(uCubeNodes[:,0], uCubeNodes[:,2], uCubeNodes[:,1], c=dispField[:,2], cmap=plt.hot(), alpha=0.5)\n",
    "plt.colorbar( img )\n",
    "ax.view_init(angle, rot)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "dimK  = 3\n",
    "model = VE( numN, dimK )\n",
    "\n",
    "def setKappaFunc(self, kappa):\n",
    "    '''kappa must be nx1'''\n",
    "    kappa = tf.reshape(kappa, [-1])\n",
    "    tf.py_function(FEBunny.setKappaCoeffs, [kappa], [])\n",
    "\n",
    "model.setKappaFunc = types.MethodType(setKappaFunc, model)\n",
    "\n",
    "\n",
    "\n",
    "def createNNs():\n",
    "    nh   = 2_500\n",
    "    numU = tf.reduce_prod( model.shapeU )\n",
    "    numK = tf.reduce_prod( model.shapeK )\n",
    "    U_K  = NeuralN('U_of_K', \n",
    "                    np.array([  numK,\n",
    "                                nh, nh, nh,\n",
    "                                numU])\n",
    "                    )\n",
    "\n",
    "    K_U  = NeuralN('K_of_U',\n",
    "                    np.array([  numU, \n",
    "                                nh, nh, nh,\n",
    "                                numK ]),\n",
    "                        )\n",
    "\n",
    "    model.initPriorNetworks(U_K=U_K, K_U=K_U)\n",
    "    model.setModePrior()\n",
    "    return \n",
    "\n",
    "model.LatentKappaPrior   = tfp.distributions.Uniform(low=tf.constant(-2., shape=model.shapeK), high=tf.constant(2., shape=model.shapeK))\n",
    "\n",
    "createNNs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
    "\n",
    "def getFromBunnyAndConvert( ):\n",
    "    Asps = FEBunny.updateMaterialStiffnessAndReturn( )\n",
    "    Asps = convert_sparse_matrix_to_sparse_tensor( Asps )\n",
    "    return [Asps.indices, tf.cast(Asps.values, floatf), Asps.dense_shape]\n",
    "\n",
    "\n",
    "Indeces, _ , DenseShape = getFromBunnyAndConvert( )\n",
    "model.setKappaFunc( model.LatentKappaPrior.mean( ) )\n",
    "PreCTriplet = getFromBunnyAndConvert( )\n",
    "SparsePre   = tf.SparseTensor(PreCTriplet[0], tf.cast(PreCTriplet[1], tf.float32), PreCTriplet[2]) \n",
    "PreCTriplet = None\n",
    "DensePreInv = tf.sparse.to_dense( SparsePre ) \n",
    "DensePreInv = tf.linalg.inv( tf.sparse.to_dense( SparsePre )  )\n",
    "DensePre = None\n",
    "PreCTriplet = None\n",
    "SparsePre = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def returnAtsSparse( ):\n",
    "    ATriple = tf.py_function(getFromBunnyAndConvert, [], [tf.int64, floatf, tf.int64])\n",
    "    def grad( dy ):\n",
    "        return dy\n",
    "    return ATriple[1], grad\n",
    "\n",
    "def logProbPhysResidual(self, uc, epsilon):\n",
    "    uc   = tf.reshape(uc, self.shapeU)\n",
    "    u    = tf.reshape(chebyToFE( uc ), [-1,1] )\n",
    "    AValues  = returnAtsSparse( ) \n",
    "    A    =   tf.SparseTensor(Indeces, AValues, DenseShape) \n",
    "    r    = DensePreInv @ ( tf.sparse.sparse_dense_matmul(A,  u) -  ForcingVect )\n",
    "    logP = - 0.5 * ( u.shape[0] * tf.math.log(epsilon**2) \n",
    "                        + tf.squeeze( tf.linalg.norm(r)**2/epsilon**2 ) + self.log2pi )\n",
    "    return logP\n",
    "model.logProbPhysResidual = types.MethodType(logProbPhysResidual, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNSolve( kappaSample ):\n",
    "\n",
    "    mu_alpha, logvar_alpha = model.priorModels['U_of_K'].Map( [tf.reshape(kappaSample, [1,-1])] ) \n",
    "    uc   = tf.reshape(mu_alpha, model.shapeU)\n",
    "    u    = chebyToFE(uc)\n",
    "    solutionField = tf.reshape(u,[-1,1])\n",
    "    \n",
    "    return solutionField, None\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "def solveFEModel( kappaSample ):\n",
    "    model.setKappaFunc( kappaSample )\n",
    "    FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1,1]) )\n",
    "    Acsc = FEBunny.updateMaterialStiffnessAndReturn( )\n",
    "    u    = sparse.linalg.spsolve(Acsc, ForcingVect)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compareNNAndFE(numTimes):\n",
    "    for i in range(numTimes):\n",
    "        kappaSample = model.LatentKappaPrior.sample(sample_shape=())\n",
    "        print(kappaSample)\n",
    "        model.setKappaFunc( kappaSample )\n",
    "        FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1]) )\n",
    "        dispField = solveFEModel( kappaSample )\n",
    "        dispField = tf.reshape(dispField, [-1,3])\n",
    "        fig = plt.figure()\n",
    "        ax  = Axes3D(fig)\n",
    "        img = ax.scatter(uCubeNodes[:,0], uCubeNodes[:,2], uCubeNodes[:,1], c=dispField[:,1], cmap=plt.hot(), alpha=0.5)\n",
    "        plt.colorbar( img )\n",
    "        ax.view_init(angle, rot)\n",
    "        plt.title('FEModel Solve')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        dispField, StdBunny = NNSolve( kappaSample )\n",
    "        dispField = tf.reshape(dispField, [-1,3])\n",
    "        print(\"dispField\", dispField)\n",
    "        fig = plt.figure()\n",
    "        ax = Axes3D(fig)\n",
    "        img = ax.scatter(uCubeNodes[:,0], uCubeNodes[:,2], uCubeNodes[:,1], c=dispField[:,1], cmap=plt.hot(), alpha=0.5)\n",
    "        plt.colorbar( img )\n",
    "        ax.view_init(angle, rot)\n",
    "        plt.title('NN Solve')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "compareNNAndFE(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps =1e-2\n",
    "\n",
    "AllEpsU = []\n",
    "AllEpsK = []\n",
    "AllEpsB = []\n",
    "\n",
    "totalTimeTraining  = 0.\n",
    "\n",
    "trainModels        = False\n",
    "\n",
    "intervalELBOsave   = 100\n",
    "\n",
    "PLOT = True\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_prior(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = model.compute_nelbo_prior(iteration)\n",
    "    for priorvars in model.priorModels['trainable_variables']:\n",
    "        tape.watch( priorvars )\n",
    "        gradients    = tape.gradient(loss, priorvars)\n",
    "        optimizer.apply_gradients(zip(gradients, priorvars))\n",
    "    return loss\n",
    "\n",
    "if trainModels:\n",
    "       \n",
    "    '''Optimization sequence'''\n",
    "    model.n_sgd      = 1\n",
    "\n",
    "    num_iterations   = tfint(50_000)\n",
    "\n",
    "    model.epsilon_r.assign( tffloat(eps) )\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        1e-3, int(num_iterations/5), 0.5, staircase=True, name=None\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam( lr, clipnorm= 5. )\n",
    "\n",
    "    elboAll       = []\n",
    "    startTraining = time.time()\n",
    "    for epoch in tf.range(0, num_iterations ):\n",
    "\n",
    "        start_time = time.time()\n",
    "        loss = train_step_prior(optimizer, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % intervalELBOsave == 0:\n",
    "\n",
    "            elboAll.append(-loss)\n",
    "\n",
    "            np.savetxt( '{}elboAll.dat'.format(dirname), np.array(elboAll) )\n",
    "            with open('{}times.dat'.format(dirname), 'a') as file:\n",
    "                file.write('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}\\n'\n",
    "                    .format(epoch, -loss, end_time - start_time))\n",
    "\n",
    "    endTraining = time.time()\n",
    "    totalTimeTraining += endTraining - startTraining\n",
    "    print(\"DONE TRAINING FOR EPSI\", eps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If you want to save or load Model Weights'''\n",
    "\n",
    "saveModelWeights = True\n",
    "loadModelWeights = False\n",
    "\n",
    "\n",
    "\n",
    "if saveModelWeights:\n",
    "    model.priorModels['U_of_K'].NN.save_weights(dirname+'U_of_K_weights.h5')\n",
    "    model.priorModels['K_of_U'].NN.save_weights(dirname+'K_of_U_weights.h5')\n",
    "    model.priorModels['U_of_K'].NN.save(dirname+'U_of_K_weights.model')\n",
    "    model.priorModels['K_of_U'].NN.save(dirname+'K_of_U_weights.model')\n",
    "    print('SAVED MODEL WEIGHTS')\n",
    "    \n",
    "\n",
    "if loadModelWeights:\n",
    "\n",
    "    model.priorModels['U_of_K'].NN = tf.keras.models.load_model(dirname+'U_of_K_weights.model')\n",
    "    model.priorModels['K_of_U'].NN = tf.keras.models.load_model(dirname+'K_of_U_weights.model')\n",
    "\n",
    "    model.priorModels['U_of_K'].NN.compile()\n",
    "    model.priorModels['K_of_U'].NN.compile()\n",
    "    # Check its architecture\n",
    "    model.priorModels['U_of_K'].NN.summary()\n",
    "    model.priorModels['K_of_U'].NN.summary()\n",
    "    print('LOADED MODEL WEIGHTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "elboAll = np.array(elboAll)\n",
    "scale = 1e8\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(range(elboAll.shape[0]),  elboAll )\n",
    "axs.set_ylim(-scale,scale)\n",
    "plt.show()\n",
    "print(elboAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeFETot = 0\n",
    "TimeNNFWTot = 0\n",
    "TimeNNInvTot = 0\n",
    "\n",
    "TotNSEFW    = 0\n",
    "TotNSEINV   = 0\n",
    "\n",
    "normSolutionFE = np.array([])\n",
    "\n",
    "from pddlvm.poisson1DPDEState import PDE_State\n",
    "yLine = fromByUnitYLine( 1 )\n",
    "print('yLine = ', yLine)\n",
    "pdeState = PDE_State(yLine, dimK=3)\n",
    "\n",
    "transform         = tfb.Chain( bijectors=[tfb.Shift(tffloat(1.)), tfb.Softplus()] )\n",
    "pdeState.kappaBij = transform\n",
    "\n",
    "\n",
    "numIndptSampels = 100\n",
    "for i in range( numIndptSampels ):\n",
    "    \n",
    "    kappaSample = model.LatentKappaPrior.sample(sample_shape=())\n",
    "    print(kappaSample)\n",
    "    model.setKappaFunc( kappaSample )\n",
    "    \n",
    "    #True Solving\n",
    "    startTimeFE = time.time()\n",
    "    FEBunny.updateMaterialStiffnessAndReturn()\n",
    "    X_ = tf.cast(FEBunny.AssembleAndSolve( ), tf.float32 )\n",
    "    normSolutionFE = np.append(normSolutionFE, np.array([tf.linalg.norm(X_)]))\n",
    "    iterTimeFE  = time.time() - startTimeFE\n",
    "    print('iterTimeFE = ', iterTimeFE)\n",
    "    TimeFETot  += iterTimeFE\n",
    "    \n",
    "    #NN Forward\n",
    "    startTimeNN = time.time()\n",
    "    mu_alpha, logvar_alpha = model.priorModels['U_of_K'].Map( [tf.reshape(kappaSample, [1,-1])] ) \n",
    "    uc     = tf.reshape(mu_alpha, model.shapeU)\n",
    "    uNN    = tf.reshape( chebyToFE(uc), [-1] )\n",
    "    iterTimeNNFW  = time.time() - startTimeNN\n",
    "    print('iterTimeNNFW = ', iterTimeNNFW)\n",
    "    TimeNNFWTot  += iterTimeNNFW\n",
    "    \n",
    "    \n",
    "    #NN Inv\n",
    "    startTimeNN = time.time()\n",
    "    mu_beta, logvar_beta = model.priorModels['K_of_U'].Map( [tf.reshape(uc, [1,-1])] ) \n",
    "    \n",
    "    mean, diagCov = pdeState.gaussChebyGaussCoeffs( tf.squeeze(mu_beta), tf.squeeze(tf.exp(logvar_beta)), x=yLine )\n",
    "    ybar, yvar    = pdeState.unscentedGaussTransf(mean, diagCov, transform=transform, k=1)\n",
    "\n",
    "    iterTimeNNINV  = time.time() - startTimeNN\n",
    "    print('iterTimeNNINV = ', iterTimeNNINV)\n",
    "    TimeNNInvTot  += iterTimeNNINV\n",
    "    pdeState.kappa = tf.squeeze( kappaSample )\n",
    "    kappaTrueOnElm = pdeState.kappa_fun(yLine)\n",
    "    \n",
    "    NSEINV     = tf.linalg.norm(  kappaTrueOnElm - ybar )**2 / tf.linalg.norm( kappaTrueOnElm )**2\n",
    "    print(\"NSEINV = \", NSEINV)\n",
    "    TotNSEINV += NSEINV\n",
    "    print(\"TotNSEINV = \", TotNSEINV)\n",
    "    \n",
    "    NSEFW     = tf.linalg.norm(  X_ - uNN )**2 / tf.linalg.norm( X_ )**2\n",
    "    print(\"NSEFW = \", NSEFW)\n",
    "    TotNSEFW += NSEFW\n",
    "    print(\"TotNSEFW = \", TotNSEFW)\n",
    "    \n",
    "    \n",
    "AvgNSEFW  = TotNSEFW / numIndptSampels\n",
    "AvgNSEINV = TotNSEINV / numIndptSampels\n",
    "\n",
    "print(\"AvgNSEFW = \", AvgNSEFW)\n",
    "print(\"AvgNSEINV = \", AvgNSEINV)\n",
    "\n",
    "print(\"TimeFETot = \", TimeFETot)\n",
    "print(\"TimeNNFWTot = \",  TimeNNFWTot)\n",
    "print(\"TimeNNInvTot = \", TimeNNInvTot)\n",
    "\n",
    "TimeFEAVG = TimeFETot / numIndptSampels\n",
    "TimeNNFWAVG = TimeNNFWTot / numIndptSampels\n",
    "TimeNNInvAVG = TimeNNInvTot / numIndptSampels\n",
    "\n",
    "print(\"TimeFEAVG = \", TimeFEAVG)\n",
    "print(\"TimeNNFWAVG = \",  TimeNNFWAVG)\n",
    "print(\"TimeNNInvAVG = \", TimeNNInvAVG)\n",
    "\n",
    "avgNormSlnFE = tf.reduce_mean(normSolutionFE)\n",
    "stddevNormSlnFE = tf.math.reduce_std(normSolutionFE)\n",
    "print('avgNormSlnFE = ', avgNormSlnFE)\n",
    "print('stddevNormSlnFE = ', stddevNormSlnFE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirnameFile = dirname+'test4'\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "\n",
    "kappaSample = model.LatentKappaPrior.sample(sample_shape=())\n",
    "print(kappaSample)\n",
    "kappaSample = tf.constant([[0.739],[ 0.167 ],[ -1.136 ]], dtype=tf.float32)\n",
    "\n",
    "model.setKappaFunc( kappaSample )\n",
    "FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "\n",
    "mu_alpha, logvar_alpha = model.priorModels['U_of_K'].Map( [tf.reshape(kappaSample, [1,-1])] ) \n",
    "uc   = tf.reshape(mu_alpha, model.shapeU)\n",
    "u    = chebyToFE(uc)\n",
    "\n",
    "solutionField = u\n",
    "FEBunny.setSolution(tf.reshape(tf.cast( solutionField , tf.float64), [-1]) )\n",
    "FEBunny.writeVTUFile('{}solutionFieldMean.vtu'.format(dirnameFile))\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "model.setKappaFunc( kappaSample )\n",
    "FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1]) )\n",
    "\n",
    "lgVarc   = tf.reshape(logvar_alpha, model.shapeU)\n",
    "Var      = tf.exp(lgVarc)\n",
    "VarBunny = chebyToFE_diagCov( Var )\n",
    "StddevBunny = tf.sqrt( tf.reshape(VarBunny, [-1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "FEBunny.setSolution( tf.reshape(tf.cast(StddevBunny, tf.float64) , [-1] ) )\n",
    "FEBunny.writeVTUFile('{}solutionFieldStddev.vtu'.format(dirnameFile))\n",
    "\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1,1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "X_ = FEBunny.AssembleAndSolve( )\n",
    "FEBunny.writeVTUFile('{}trueSolution.vtu'.format(dirnameFile))\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1,1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "FEBunny.setSolution( tf.abs(X_ - tf.reshape(tf.cast( solutionField , tf.float64), [-1]) )  ) \n",
    "FEBunny.writeVTUFile('{}absErrorDisp.vtu'.format(dirnameFile))\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "FEBunny.setSolution(tf.reshape(tf.cast( solutionField , tf.float64), [-1]) )\n",
    "mu_beta, logvar_beta = model.priorModels['K_of_U'].Map( [tf.reshape(mu_alpha, [1,-1])] ) \n",
    "FEBunny.setKappaCoeffs( tf.reshape(mu_beta,[-1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "FEBunny.setSolution(tf.reshape(tf.cast( solutionField , tf.float64), [-1]) )\n",
    "FEBunny.writeVTUFile('{}kappaMeanReconstructed.vtu'.format(dirnameFile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pddlvm.poisson1DPDEState import PDE_State\n",
    "yLine = fromByUnitYLine( 1 )\n",
    "print('yLine = ', yLine)\n",
    "pdeState = PDE_State(yLine, dimK=3)\n",
    "\n",
    "transform     = tfb.Chain( bijectors=[tfb.Shift(tffloat(1.)), tfb.Softplus()] )\n",
    "mean, diagCov = pdeState.gaussChebyGaussCoeffs( tf.squeeze(mu_beta), tf.squeeze(tf.exp(logvar_beta)), x=yLine )\n",
    "ybar, yvar    = pdeState.unscentedGaussTransf(mean, diagCov, transform=transform, k=1)\n",
    "\n",
    "YBAR          = tf.reshape(tf.tile(ybar[:,None], [1, 3]), [-1])\n",
    "YSTD          = tf.sqrt( tf.reshape(tf.tile(yvar[:,None], [1, 3]), [-1]) )\n",
    "print('YBAR = ', YBAR)\n",
    "print('YSTD = ', YSTD)\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "FEBunny.setKappaCoeffs( tf.reshape(kappaSample,[-1]) )\n",
    "A =  FEBunny.updateMaterialStiffnessAndReturn()\n",
    "FEBunny.setSolution(tf.reshape(tf.cast( YBAR , tf.float64), [-1]) )\n",
    "FEBunny.writeVTUFile('{}kappaMeanReconstructed--unscented.vtu'.format(dirnameFile))\n",
    "\n",
    "FEBunny = bunny.Bunny()\n",
    "FEBunny.initialize( 0 )\n",
    "FEBunny.setSolution(tf.reshape(tf.cast( YSTD , tf.float64), [-1]) )\n",
    "FEBunny.writeVTUFile('{}kappaVarReconstructed--unscented.vtu'.format(dirnameFile))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f27e755c6e9f953092984d2fa7d5cd43e84a5cfdd14fc533980b318a0988c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
