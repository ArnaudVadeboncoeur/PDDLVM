{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_inter_op_parallelism_threads(14)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(14)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=6000)])\n",
    "\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "except:\n",
    "  # Invalid device or cannot modify logical devices once initialized.\n",
    "  pass\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pddlvm.utilities import tf, tfp, np, plt, tfb, floatf, tffloat, tfint, updateTfFloat,  _0\n",
    "from pddlvm.VEModel import VE\n",
    "from pddlvm.NeuralNet import NeuralN\n",
    "from pddlvm.poisson1DPDEState import PDE_State\n",
    "tf.random.set_seed(42)\n",
    "import time\n",
    "print(tffloat(0.))\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "prefix = 'NonLinHeatPINNPDDLVM'\n",
    "dirname = '{}/'.format(prefix)\n",
    "os.makedirs(os.path.dirname(dirname), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimZ      = 2\n",
    "dimDomain = 2\n",
    "dimU      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D grid\n",
    "nx = 100\n",
    "nt = 200\n",
    "piTF = tf.constant(np.pi, dtype=tf.float32)\n",
    "xi = tf.linspace(0., 2*piTF, nx)\n",
    "ti = tf.linspace(0., 2., nt)\n",
    "\n",
    "xmGrid, tmGrid = np.meshgrid(xi, ti)\n",
    "xmGridBody, tmGridBody = np.meshgrid(xi[1:-1], ti[1:])\n",
    "nxBody  = xi[1:-1].shape[0]\n",
    "ntBody  = ti[1:].shape[0]\n",
    "print((nxBody, ntBody))\n",
    "print(nxBody * ntBody)\n",
    "\n",
    "\n",
    "xmBody = tf.reshape(xmGridBody, [-1, 1])\n",
    "tmBody = tf.reshape(tmGridBody, [-1, 1])\n",
    "\n",
    "xm     = tf.reshape(xmGrid, [-1, 1])\n",
    "tm     = tf.reshape(tmGrid, [-1, 1])\n",
    "\n",
    "x = tf.reshape(xi, [-1,1])\n",
    "t = tf.reshape(ti, [-1,1])\n",
    "\n",
    "xbl = tf.repeat(x[0, 0], nt)[:, None]\n",
    "xbr = tf.repeat(x[-1,0], nt)[:, None]\n",
    "t0  = tf.repeat(t[0, 0], nx)[:, None]\n",
    "\n",
    "xtbl = tf.concat([xbl, ti[:, None]], 1)\n",
    "xtbr = tf.concat([xbr, ti[:, None]], 1)\n",
    "xt0  = tf.concat([xi[:, None], t0], 1)\n",
    "\n",
    "allICBC = tf.concat([xtbl, xtbr, xt0], 0)\n",
    "\n",
    "print(xmGridBody.shape)\n",
    "print(allICBC.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh     = 100\n",
    "U_XTK  = NeuralN('U_of_XTK', \n",
    "                np.array([  dimZ + dimDomain,\n",
    "                            nh, nh, nh, nh,\n",
    "                            dimU])\n",
    "                )\n",
    "\n",
    "K_U  = NeuralN('K_of_U',  np.array([  1, 50, dimZ]) )\n",
    "# New definition of NeuralN for K_U; patched object outside class as conv not yet supported in class\n",
    "K_U.NN = tf.keras.Sequential(\n",
    "    [   tf.keras.layers.Reshape((nxBody,ntBody, 1), input_shape=(1, nxBody*ntBody)),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=8, kernel_size=4, strides=(2, 2), activation='swish'),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=16, kernel_size=4, strides=(2, 2), activation='swish'),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=32, kernel_size=4, strides=(2, 2), activation='swish'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(500),\n",
    "        tf.keras.layers.Dense(4),\n",
    "    ]\n",
    "    )\n",
    "K_U.NN.compile( )\n",
    "K_U.NN.summary( )\n",
    "#New definition of MAP for K_U; patched object outside class as conv not yet supported in class\n",
    "from types import MethodType\n",
    "def Map(self, varIn):    \n",
    "    varIn  = self.transf_forward(varIn)\n",
    "    mapped = self.NN( varIn[None,...] )\n",
    "    mean, logvar = mapped[:,:self.layout[-1]], mapped[:,self.layout[-1]:]\n",
    "    tf.debugging.assert_all_finite(mean, 'mean not finite')\n",
    "    tf.debugging.assert_all_finite(logvar, 'logvar not finite')\n",
    "    logvar = self.dBoundwalpha_log( logvar )\n",
    "    mean   = tf.cast(mean, floatf)\n",
    "    logvar = tf.cast(logvar, floatf)\n",
    "    return mean, logvar\n",
    "K_U.Map = MethodType(Map, K_U)\n",
    "\n",
    "trainableVars = [U_XTK.NN.trainable_variables, K_U.NN.trainable_variables]\n",
    "epsilon_r     = tf.Variable(tf.constant(1e-2), trainable=False)\n",
    "# Z = gamma, kappa\n",
    "LatentPriorZ      = tfp.distributions.Uniform(low=tffloat([1., 1.]), high=tffloat([5., 5.]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize( mean, logvar):\n",
    "    eps = tf.random.normal(shape=[mean.shape[0], mean.shape[1]], dtype=floatf)\n",
    "    z = eps * tf.exp(logvar * .5) + mean\n",
    "    tf.debugging.assert_all_finite(z, 'z reparam not finite')\n",
    "    return z    \n",
    "    \n",
    "log2pi = tf.math.log( tf.constant(2* np.pi, dtype=tf.float32))\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    return tf.reduce_sum( -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "def mu_of_u( U, kappa ):\n",
    "    # thermal conductivity as funciton of t\n",
    "    return (U * kappa**2 + 1) / kappa\n",
    "\n",
    "def residualFunction( z_i ):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as t1:\n",
    "        t1.watch(xmBody)\n",
    "        with tf.GradientTape(watch_accessed_variables=False, persistent=True) as t2:\n",
    "            t2.watch(xmBody)\n",
    "            t2.watch(tmBody)\n",
    "            mean_alpha, logvar_alpha = U_XTK.Map( [xmBody, tmBody, tf.tile(z_i, [xmBody.shape[0], 1])] )\n",
    "            us = tf.reshape(reparameterize(mean_alpha, logvar_alpha), [-1,1])\n",
    "        grad_x_Us = tf.reshape(t2.gradient(us, xmBody), [-1,1] )\n",
    "        grad_t_Us = tf.reshape(t2.gradient(us, tmBody), [-1,1] )\n",
    "        muU       = mu_of_u( us, tf.squeeze(z_i[0, 1]) )\n",
    "        muUGradUX = muU * grad_x_Us\n",
    "    gradMuUGradUX = tf.reshape(t1.gradient(muUGradUX, xmBody), [-1,1] )\n",
    "    residualBody = - grad_t_Us + 1./tf.squeeze(z_i[0, 0]) * gradMuUGradUX\n",
    "\n",
    "    mean_alphaICBD, logvar_alphaICBD = U_XTK.Map( [allICBC, tf.tile(z_i, [allICBC.shape[0], 1])] )\n",
    "    usICBD = tf.reshape(reparameterize(mean_alphaICBD, logvar_alphaICBD), [-1,1])\n",
    "    uxl          = usICBD[:nt,     0] \n",
    "    uxr          = usICBD[nt:2*nt, 0] \n",
    "    uxt0         = usICBD[2*nt: ,  0] \n",
    "    u0, bcLeft, bcRight = tf.math.sin(xi) + 1., 1. , 1.\n",
    "    residualICBC = tf.reshape(tf.concat([ ( uxt0 - u0 ), ( uxl - bcLeft ), ( uxr - bcRight ) ], 0), [-1,1])\n",
    "\n",
    "    residual = tf.concat([residualBody, residualICBC], 0)\n",
    "\n",
    "    logP_alpha_u_Z  = log_normal_pdf( us , mean_alpha, logvar_alpha, raxis=0)\n",
    "\n",
    "    return us, residual, logP_alpha_u_Z\n",
    "\n",
    "\n",
    "def ELBO( ):\n",
    "    \n",
    "    z_i = tf.reshape( LatentPriorZ.sample( ) , [-1, dimZ])\n",
    "\n",
    "    us, residual, logP_alpha_u_Z = residualFunction( z_i )\n",
    "\n",
    "    logVarEpsilonVectBody = tf.repeat(2*tf.math.log(epsilon_r), tf.reduce_prod(xmBody.shape) )[:, None]\n",
    "    logVarEpsilonVectBCIC = tf.repeat(2*tf.math.log(epsilon_r/10.), allICBC.shape[0] )[:, None]\n",
    "    logVarEpsilonVect     = tf.concat([logVarEpsilonVectBody , logVarEpsilonVectBCIC ], 0)\n",
    "\n",
    "    logP_r   = log_normal_pdf( residual, tf.constant(0., shape=residual.shape), logVarEpsilonVect, raxis=0 )\n",
    "\n",
    "    mean_beta, logvar_beta = K_U.Map( tf.reshape(us, [1,-1]) )\n",
    "\n",
    "    logP_beta_Z_u          = log_normal_pdf( z_i, mean_beta, logvar_beta, raxis=1 ) #this is correct dimension\n",
    "\n",
    "    elbo = tf.reduce_mean( logP_r + logP_beta_Z_u -  logP_alpha_u_Z )\n",
    "\n",
    "    return elbo\n",
    "\n",
    "print(ELBO())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_prior(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = - ELBO( )\n",
    "    for vars in trainableVars:\n",
    "        gradients = tape.gradient(loss, vars)\n",
    "        optimizer.apply_gradients(zip(gradients, vars))\n",
    "    return loss\n",
    "\n",
    "num_iterations   = tfint(500_000)\n",
    "\n",
    "epsilon_r.assign( tf.constant(1e-2) )\n",
    "\n",
    "intervalELBOsave = 1000\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam( 1e-3 )\n",
    "\n",
    "elboAll     = []\n",
    "startTraining = time.time()\n",
    "for iteration in tf.range(0, num_iterations ):\n",
    "\n",
    "    start_time = time.time()\n",
    "    loss = train_step_prior(optimizer, iteration)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    if iteration % intervalELBOsave == 0:\n",
    "        elboAll.append(-loss)\n",
    "        print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "           .format(iteration, -loss, end_time - start_time))\n",
    "\n",
    "endTraining = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(elboAll))\n",
    "plt.ylim(-1e6, 1e6)\n",
    "plt.show()\n",
    "np.savetxt(dirname+'ELBO.dat', np.array(elboAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_i = tf.reshape( LatentPriorZ.sample( ) , [-1, dimZ])\n",
    "\n",
    "z_i = tf.constant([[5., 5.]])\n",
    "\n",
    "# for z_i in z:\n",
    "mean_alpha, logvar_alpha = U_XTK.Map( [xm, tm, tf.tile(z_i, [xm.shape[0], 1])] )\n",
    "stddev_alpha = tf.exp(logvar_alpha*0.5) * 1\n",
    "\n",
    "allI = np.array(range(nt))[::10]\n",
    "colors = plt.cm.viridis(np.linspace(0,1,allI.shape[0]))\n",
    "fig, ax = plt.subplots()\n",
    "ic = 0\n",
    "c = np.arange(1, allI.shape[0] + 1)\n",
    "cmap = plt.cm.get_cmap('viridis', allI.shape[0])\n",
    "\n",
    "dummie_cax = ax.scatter(c, t[::10, 0], c=t[::10, 0], cmap=cmap)\n",
    "ax.cla()\n",
    "for i in allI:\n",
    "    im = ax.plot(xm[i*nx:(i+1)*nx, 0], mean_alpha[i*nx:(i+1)*nx], c=colors[ic])\n",
    "    ax.fill_between( tf.squeeze(xm[i*nx:(i+1)*nx, 0]),  tf.squeeze(mean_alpha[i*nx:(i+1)*nx] + 2* stddev_alpha[i*nx:(i+1)*nx]), \n",
    "                     tf.squeeze(mean_alpha[i*nx:(i+1)*nx] - 2* stddev_alpha[i*nx:(i+1)*nx]), color=colors[ic], alpha=0.5 )\n",
    "    ic+=1\n",
    "\n",
    "fig.colorbar(dummie_cax, label=r'$t$')\n",
    "ax.set_ylabel(r'$u$')\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_title(r'$u(x,t) \\pm 2\\sigma(x,t)$')\n",
    "plt.show()\n",
    "\n",
    "SAVE = dirname\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(5, 2.5))\n",
    "im1 = ax.contourf(tmGrid, xmGrid, tf.reshape(mean_alpha, [nt, nx]), 100)\n",
    "ax.set_xlabel(r'$t$')\n",
    "ax.set_ylabel(r'$x$')\n",
    "fig.colorbar(im1, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(5, 2.5))\n",
    "im2 = ax.contourf(tmGrid, xmGrid, tf.reshape(2*tf.exp(logvar_alpha*0.5), [nt, nx]), 100)\n",
    "ax.set_xlabel(r'$t$')\n",
    "ax.set_ylabel(r'$x$')\n",
    "fig.colorbar(im2, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "_, finalRes, _ = residualFunction( z_i )\n",
    "print(\"finalRes = \", tf.reduce_sum(finalRes ** 2)/finalRes.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelWeights = False\n",
    "loadModelWeights = False\n",
    "\n",
    "if saveModelWeights:\n",
    "    U_XTK.NN.save_weights(dirname+'U_of_K_weights.h5')\n",
    "    K_U.NN.save_weights(dirname+'K_of_U_weights.h5')\n",
    "    U_XTK.NN.save(dirname+'U_of_K_weights.model')\n",
    "    K_U.NN.save(dirname+'K_of_U_weights.model')\n",
    "    print('SAVED MODEL WEIGHTS')\n",
    "    \n",
    "\n",
    "if loadModelWeights:\n",
    "\n",
    "    U_XTK.NN = tf.keras.models.load_model(dirname+'U_of_K_weights.model')\n",
    "    K_U.NN   = tf.keras.models.load_model(dirname+'K_of_U_weights.model')\n",
    "    U_XTK.NN.compile()\n",
    "    K_U.NN.compile()\n",
    "    # Check its architecture\n",
    "    U_XTK.NN.summary()\n",
    "    K_U.NN.summary()\n",
    "    print('LOADED MODEL WEIGHTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGamma = 100\n",
    "nKappa = 100\n",
    "\n",
    "gamma = tf.linspace(0.1, 12., nGamma)\n",
    "kappa = tf.linspace(0.1, 12., nKappa)\n",
    "\n",
    "gammaGrid, kappaGrid = np.meshgrid(gamma, kappa)\n",
    "\n",
    "gammam     = tf.reshape(gammaGrid, [-1, 1])\n",
    "kappam     = tf.reshape(kappaGrid, [-1, 1])\n",
    "Params     = tf.concat([gammam, kappam], 1)\n",
    "\n",
    "paramSpaceResidual = []\n",
    "paramSpaceStddev   = [] \n",
    "betastddev         = []\n",
    "zResidual          = [] \n",
    "betastddevMEAN     = []\n",
    "\n",
    "for i in range(nGamma * nKappa):\n",
    "\n",
    "    z_i = Params[i, :][None, :]\n",
    "\n",
    "    mean_alpha, logvar_alpha = U_XTK.Map( [xmBody, tmBody, tf.tile(z_i, [xmBody.shape[0], 1])] )\n",
    "    _, pdeResidual, _ = residualFunction( z_i )\n",
    "    pdeResidual = tf.reduce_sum(pdeResidual ** 2)/pdeResidual.shape[0]\n",
    "    paramSpaceResidual.append( pdeResidual )\n",
    "    print(pdeResidual)\n",
    "\n",
    "    stdAVG      = tf.reduce_mean( 2*tf.exp( logvar_alpha * 0.5 ) )\n",
    "    paramSpaceStddev.append( stdAVG )\n",
    "\n",
    "    mean_beta, logvar_beta = K_U.Map( tf.reshape(mean_alpha, [1,-1]) )\n",
    "    print(\"mean_beta, logvar_beta = \",mean_beta, logvar_beta)\n",
    "    NSEZ = ( tf.linalg.norm( z_i - mean_beta) / tf.linalg.norm( z_i ) ) ** 2\n",
    "    zResidual.append( NSEZ )\n",
    "    betastdAVG      = tf.reduce_mean( 2*tf.exp( logvar_beta[0, 1] * 0.5 ) )\n",
    "    betastddev.append( betastdAVG )\n",
    "    betastddevMEAN.append( mean_beta[0,0] )\n",
    "\n",
    "paramSpaceResidualNP = np.log( np.array( paramSpaceResidual ).reshape(-1,1) )\n",
    "paramSpaceStddevNP   = np.log( np.array( paramSpaceStddev ).reshape(-1,1) )\n",
    "\n",
    "zResidualNP          = np.log( np.array( zResidual ).reshape(-1,1) )\n",
    "betastddevNP         = np.log( np.array( betastddev ).reshape(-1,1) )\n",
    "betastddevMEANNP     = np.array( betastddevMEAN ).reshape(-1,1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameterBox = np.array([[1,1], [1, 5], [5, 5], [5, 1], [1, 1]])\n",
    "SAVE = dirname\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=False, figsize=(6, 5))\n",
    "im1 = ax.contourf(gammaGrid, kappaGrid, tf.reshape(paramSpaceResidualNP, [nGamma, nKappa]), 200)\n",
    "ax.plot(parameterBox[:,0], parameterBox[:,1], c='w')\n",
    "ax.set_xlabel(r'$\\gamma$')\n",
    "ax.set_ylabel(r'$\\kappa$')\n",
    "fig.colorbar(im1, ax=ax)\n",
    "plt.tight_layout( )\n",
    "plt.savefig( '{}gammaKappaGridPDEResidual-1210.png'.format(SAVE), dpi=300 )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=False, figsize=(6, 5))\n",
    "im2 = ax.contourf(gammaGrid, kappaGrid, tf.reshape(paramSpaceStddevNP,  [nGamma, nKappa]), 200)\n",
    "ax.plot(parameterBox[:,0], parameterBox[:,1], c='w')\n",
    "ax.set_xlabel(r'$\\gamma$')\n",
    "ax.set_ylabel(r'$\\kappa$')\n",
    "plt.tight_layout( )\n",
    "fig.colorbar(im2, ax=ax)\n",
    "plt.savefig( '{}gammaKappaGridUstddev-1210.png'.format(SAVE), dpi=300 )\n",
    "plt.show( )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGamma = 20\n",
    "nKappa = 20\n",
    "\n",
    "gamma = tf.linspace(0.5, 7., nGamma)\n",
    "kappa = tf.linspace(0.5, 7., nKappa)\n",
    "\n",
    "gammaGrid, kappaGrid = np.meshgrid(gamma, kappa)\n",
    "\n",
    "gammam     = tf.reshape(gammaGrid, [-1, 1])\n",
    "kappam     = tf.reshape(kappaGrid, [-1, 1])\n",
    "Params     = tf.concat([gammam, kappam], 1)\n",
    "\n",
    "paramSpaceResidual = []\n",
    "paramSpaceStddev   = [] \n",
    "betastddev         = []\n",
    "zResidual          = [] \n",
    "\n",
    "for i in range(nGamma * nKappa):\n",
    "\n",
    "    z_i = Params[i, :][None, :]\n",
    "\n",
    "    mean_alpha, logvar_alpha = U_XTK.Map( [xmBody, tmBody, tf.tile(z_i, [xmBody.shape[0], 1])] )\n",
    "    _, pdeResidual, _ = residualFunction( z_i )\n",
    "    pdeResidual = tf.reduce_sum(pdeResidual ** 2)/pdeResidual.shape[0]\n",
    "    paramSpaceResidual.append( pdeResidual )\n",
    "    print(pdeResidual)\n",
    "\n",
    "    stdAVG      = tf.reduce_mean( 2*tf.exp( logvar_alpha * 0.5 ) )\n",
    "    paramSpaceStddev.append( stdAVG )\n",
    "\n",
    "    mean_beta, logvar_beta = K_U.Map( tf.reshape(mean_alpha, [1,-1]) )\n",
    "    NSEZ = ( tf.linalg.norm( z_i - mean_beta) / tf.linalg.norm( z_i ) ) ** 2\n",
    "    zResidual.append( NSEZ )\n",
    "    betastdAVG      = tf.reduce_mean( 2*tf.exp( logvar_beta * 0.5 ) )\n",
    "    betastddev.append( betastdAVG )\n",
    "\n",
    "paramSpaceResidualNP = np.log( np.array( paramSpaceResidual ).reshape(-1,1) )\n",
    "paramSpaceStddevNP   = np.log( np.array( paramSpaceStddev ).reshape(-1,1) )\n",
    "zResidualNP          = np.log( np.array( zResidual ).reshape(-1,1) )\n",
    "betastddevNP         = np.log( np.array( betastddev ).reshape(-1,1) )\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, figsize=(20, 6))\n",
    "\n",
    "parameterBox = np.array([[1,1], [1, 5], [5, 5], [5, 1], [1, 1]])\n",
    "\n",
    "im3 = ax[0].contourf(gammaGrid, kappaGrid, tf.reshape(zResidualNP,  [nGamma, nKappa]), 200)\n",
    "ax[0].set_title(r'$\\log NSE_{\\mathbf{z}}(\\gamma, \\kappa)$')\n",
    "ax[0].plot(parameterBox[:,0], parameterBox[:,1], c='w')\n",
    "ax[0].set_xlabel(r'$\\gamma$')\n",
    "ax[0].set_ylabel(r'$\\kappa$')\n",
    "\n",
    "im4 = ax[1].contourf(gammaGrid, kappaGrid, tf.reshape(betastddevNP,  [nGamma, nKappa]), 200)\n",
    "ax[1].set_title(r'$\\log 2\\bar{\\sigma}_{\\beta}(\\gamma, \\kappa)$')\n",
    "ax[1].plot(parameterBox[:,0], parameterBox[:,1], c='k')\n",
    "ax[1].set_xlabel(r'$\\gamma$')\n",
    "ax[1].set_ylabel(r'$\\kappa$')\n",
    "\n",
    "fig.colorbar(im3, ax=ax[0])\n",
    "fig.colorbar(im4, ax=ax[1])\n",
    "plt.tight_layout()\n",
    "\n",
    "SAVE = dirname+'inRangePriors'\n",
    "\n",
    "extent = ax[0].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "\n",
    "extent = ax[1].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURE PINN SECTION\n",
    "\n",
    "layout = np.array([4,100,100,100,100, 1])\n",
    "PINN = tf.keras.Sequential( )\n",
    "activation = tf.keras.activations.swish\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "for i in range(1, layout.shape[0] - 1):\n",
    "    if i == 1: \n",
    "        print('first layer')\n",
    "        PINN.add(tf.keras.layers.Dense(layout[i], input_dim = layout[0], activation = activation, kernel_initializer=initializer))\n",
    "    else:\n",
    "        print('inner layer ', i)\n",
    "        PINN.add(tf.keras.layers.Dense(layout[i], activation = activation, kernel_initializer=initializer))\n",
    "print('last layer')\n",
    "PINN.add(tf.keras.layers.Dense(  layout[-1]  ))\n",
    "PINN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGammaPinn = 50\n",
    "nKappaPinn = 50\n",
    "\n",
    "gammaPinn = tf.linspace(1., 5., nGammaPinn)\n",
    "kappaPinn = tf.linspace(1., 5., nKappaPinn)\n",
    "\n",
    "gammaGridPinn, kappaGridPinn = np.meshgrid(gammaPinn, kappaPinn)\n",
    "\n",
    "gammamPinn     = tf.reshape(gammaGridPinn, [-1, 1])\n",
    "kappamPinn     = tf.reshape(kappaGridPinn, [-1, 1])\n",
    "ParamsPinn     = tf.concat([gammamPinn, kappamPinn], 1)\n",
    "\n",
    "\n",
    "num_iterations = 500_000\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam( 1e-3 )\n",
    "\n",
    "def modelNNPINN(x, t, z):\n",
    "    return PINN( tf.concat([x, t, z], 1) )\n",
    "def modelPDDLVMMeanForward(x, t, z):\n",
    "    mean_alpha, logvar_alpha = U_XTK.Map( [x, t, z] )\n",
    "    return mean_alpha\n",
    "modelFUNC = modelNNPINN\n",
    "\n",
    "def residualFunctionPINN( z_i ):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as t1:\n",
    "        t1.watch(xmBody)\n",
    "        with tf.GradientTape(watch_accessed_variables=False, persistent=True) as t2:\n",
    "            t2.watch(xmBody)\n",
    "            t2.watch(tmBody)\n",
    "            U = modelFUNC( xmBody, tmBody, tf.tile(z_i, [xmBody.shape[0], 1]) )\n",
    "        grad_x_Us = tf.reshape(t2.gradient(U, xmBody), [-1,1] )\n",
    "        grad_t_Us = tf.reshape(t2.gradient(U, tmBody), [-1,1] )\n",
    "        muU       = mu_of_u( U, tf.squeeze(z_i[0, 1]) )\n",
    "        muUGradUX = muU * grad_x_Us\n",
    "    gradMuUGradUX = tf.reshape(t1.gradient(muUGradUX, xmBody), [-1,1] )\n",
    "    residualBody = - grad_t_Us + 1./tf.squeeze(z_i[0, 0]) * gradMuUGradUX\n",
    "    residualBodySummed = tf.reduce_sum(residualBody ** 2) / residualBody.shape[0]\n",
    "\n",
    "    UCICBD = modelFUNC( allICBC[:, 0][:, None], allICBC[:, 1][:, None], tf.tile(z_i, [allICBC.shape[0], 1]) ) \n",
    "    uxl          = UCICBD[:nt,     0] \n",
    "    uxr          = UCICBD[nt:2*nt, 0] \n",
    "    uxt0         = UCICBD[2*nt: ,  0] \n",
    "    u0, bcLeft, bcRight = tf.math.sin(xi) + 1., 1. , 1.\n",
    "\n",
    "    residualBC   = tf.reduce_sum( ( uxl - bcLeft ) ** 2 + ( uxr - bcRight ) ** 2 ) / (uxl.shape[0] + uxr.shape[0] )\n",
    "    residualIC   = tf.reduce_sum( ( uxt0 - u0 ) ** 2 ) / (uxt0.shape[0] )\n",
    "    residual     = residualBodySummed + residualBC + residualIC\n",
    "\n",
    "    return residual\n",
    "\n",
    "@tf.function\n",
    "def train_step_pinn(optimizer, z_i):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = residualFunctionPINN( z_i )\n",
    "        gradients = tape.gradient(loss, PINN.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, PINN.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "LOSS = []\n",
    "for i in tf.range(num_iterations):\n",
    "    index = i % ParamsPinn.shape[0]\n",
    "    loss = train_step_pinn( optimizer, ParamsPinn[index, :][None, :] )\n",
    "    LOSS.append( tf.squeeze(loss) )\n",
    "    if i % 1000 == 0:\n",
    "        print(\"iter \", i, \" \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelWeights = False\n",
    "loadModelWeights = False\n",
    "\n",
    "if saveModelWeights:\n",
    "    PINN.compile()\n",
    "    PINN.save(dirname+'PINN_weights.model')\n",
    "    print('SAVED MODEL WEIGHTS')\n",
    "    \n",
    "\n",
    "if loadModelWeights:\n",
    "    PINN = tf.keras.models.load_model(dirname+'PINN_weights.model')    \n",
    "    PINN.compile()\n",
    "    print('LOADED MODEL WEIGHTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGamma = 100\n",
    "nKappa = 100\n",
    "\n",
    "gamma = tf.linspace(0.1, 12., nGamma)\n",
    "kappa = tf.linspace(0.1, 12., nKappa)\n",
    "\n",
    "gammaGrid, kappaGrid = np.meshgrid(gamma, kappa)\n",
    "\n",
    "gammam     = tf.reshape(gammaGrid, [-1, 1])\n",
    "kappam     = tf.reshape(kappaGrid, [-1, 1])\n",
    "Params     = tf.concat([gammam, kappam], 1)\n",
    "\n",
    "paramSpaceResidualPINN = []\n",
    "paramSpaceResidualMEANPDDLVM = []\n",
    "\n",
    "\n",
    "modelFUNC = modelNNPINN\n",
    "for i in range(nGamma * nKappa):\n",
    "    z_i = Params[i, :][None, :]\n",
    "    paramSpaceResidualPINN.append( residualFunctionPINN( z_i ))\n",
    "\n",
    "modelFUNC = modelPDDLVMMeanForward\n",
    "for i in range(nGamma * nKappa):\n",
    "    z_i = Params[i, :][None, :]\n",
    "    paramSpaceResidualMEANPDDLVM.append( residualFunctionPINN( z_i ))\n",
    "\n",
    "\n",
    "paramSpaceResidualPINNNP = np.log( np.array( paramSpaceResidualPINN ).reshape(-1,1) )\n",
    "paramSpaceResidualMEANPDDLVMNP   = np.log( np.array( paramSpaceResidualMEANPDDLVM ).reshape(-1,1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameterBox = np.array([[1,1], [1, 5], [5, 5], [5, 1], [1, 1]])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=False, figsize=(6, 5))\n",
    "im1 = ax.contourf(gammaGrid, kappaGrid, tf.reshape(paramSpaceResidualPINNNP, [nGamma, nKappa]), 200)\n",
    "ax.plot(parameterBox[:,0], parameterBox[:,1], c='w')\n",
    "ax.set_xlabel(r'$\\gamma$')\n",
    "ax.set_ylabel(r'$\\kappa$')\n",
    "fig.colorbar(im1, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig( '{}paramSpaceResidualPINNNP2.png'.format(dirname) )\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=False, figsize=(6, 5))\n",
    "im2 = ax.contourf(gammaGrid, kappaGrid, tf.reshape(paramSpaceResidualMEANPDDLVMNP,  [nGamma, nKappa]), 200)\n",
    "ax.plot(parameterBox[:,0], parameterBox[:,1], c='w')\n",
    "ax.set_xlabel(r'$\\gamma$')\n",
    "ax.set_ylabel(r'$\\kappa$')\n",
    "plt.tight_layout()\n",
    "fig.colorbar(im2, ax=ax)\n",
    "plt.savefig( '{}paramSpaceResidualMEANPDDLVMNP2.png'.format(dirname) )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGamma = 100\n",
    "nKappa = 100\n",
    "\n",
    "gamma = tf.linspace(1., 5., nGamma)\n",
    "kappa = tf.linspace(1., 5., nKappa)\n",
    "\n",
    "gammaGrid, kappaGrid = np.meshgrid(gamma, kappa)\n",
    "\n",
    "gammam     = tf.reshape(gammaGrid, [-1, 1])\n",
    "kappam     = tf.reshape(kappaGrid, [-1, 1])\n",
    "Params     = tf.concat([gammam, kappam], 1)\n",
    "\n",
    "paramSpaceResidualPINN = []\n",
    "paramSpaceResidualMEANPDDLVM = []\n",
    "\n",
    "\n",
    "modelFUNC = modelNNPINN\n",
    "for i in range(nGamma * nKappa):\n",
    "    z_i = Params[i, :][None, :]\n",
    "    paramSpaceResidualPINN.append( residualFunctionPINN( z_i ))\n",
    "\n",
    "modelFUNC = modelPDDLVMMeanForward\n",
    "for i in range(nGamma * nKappa):\n",
    "    z_i = Params[i, :][None, :]\n",
    "    paramSpaceResidualMEANPDDLVM.append( residualFunctionPINN( z_i ))\n",
    "\n",
    "\n",
    "paramSpaceResidualPINNNP = np.log( np.array( paramSpaceResidualPINN ).reshape(-1,1) )\n",
    "paramSpaceResidualMEANPDDLVMNP   = np.log( np.array( paramSpaceResidualMEANPDDLVM ).reshape(-1,1) )\n",
    "\n",
    "print( 'meanInSquarePINN = ', np.mean(np.array(paramSpaceResidualPINN)) )\n",
    "print( 'meanInSquarePDDLVM = ', np.mean(np.array(paramSpaceResidualMEANPDDLVM)) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f27e755c6e9f953092984d2fa7d5cd43e84a5cfdd14fc533980b318a0988c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
