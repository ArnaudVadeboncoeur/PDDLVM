{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n",
    "from pddlvm.utilities import tf, tfp, np, plt, tfb, floatf, tffloat, tfint, updateTfFloat,  _0\n",
    "updateTfFloat ( tf.float32 )\n",
    "\n",
    "from pddlvm.poisson1DPDEState import PDE_State\n",
    "from pddlvm.poisson1DSolver import Solver \n",
    "from pddlvm.NeuralNet import NeuralN\n",
    "from pddlvm.VEModel import VE\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import time\n",
    "\n",
    "print(tffloat(0.))\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "# This is the one used for PDDLVM paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create PDEState Object with Cheby Num terms (-1 for degree)'''\n",
    "omegaLength = 2.0\n",
    "numFElems   = 100\n",
    "numFENodes  = numFElems + 1\n",
    "xFE = tffloat( tf.linspace( 0., omegaLength, numFElems + 1) ) - 1.\n",
    "\n",
    "pdeState = PDE_State(xFE, dimK=4, dimF=1, dimU=8)\n",
    "'''Modify pdeState Bijcetor for kappa'''\n",
    "pdeState.kappaBij   = tfb.Chain( bijectors=[tfb.Shift(tffloat(1.)), tfb.Softplus()] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create solver Object'''\n",
    "solver = Solver( pdeState, xFE, isNonLinear=True )\n",
    "\n",
    "'''Modify pdeState.stress-strain for nonlinear Youngs Modulus'''\n",
    "import types\n",
    "def stress_strain_nonLinear(self, index, kappa, u_trial):\n",
    "    #print('custom stress-strain')\n",
    "    dudx = ( u_trial[index] - u_trial[index+1]) / (self.pdeState.xFE[index] - self.pdeState.xFE[index+1])\n",
    "    return (tf.keras.activations.sigmoid(tf.math.abs(dudx)) + kappa*5. ) /10.\n",
    "solver.stress_strain = types.MethodType(stress_strain_nonLinear, solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VE( pdeState, solver )\n",
    "\n",
    "def createNNsPrior():\n",
    "    dimKFBlBr = model.dimK + model.dimF + model.dimBl + model.dimBr\n",
    "    nh = 50\n",
    "    U_KFBlBr  = NeuralN('U_of_KFBlBr', \n",
    "                    np.array([dimKFBlBr,\n",
    "                              nh, nh, nh, nh,\n",
    "                              model.dimU])\n",
    "                    )\n",
    "\n",
    "    k  = model.dimK\n",
    "    bl = k  + model.dimBl\n",
    "    br = bl + model.dimBr\n",
    "    Z_UF     = NeuralN('Z_of_UF',\n",
    "                    np.array([pdeState.dimU + model.dimF, \n",
    "                                nh, nh, nh, nh, \n",
    "                                model.dimK + model.dimBl + model.dimBr]),\n",
    "                    multOutputLayout = {'K': tf.range(0,k),\n",
    "                                        'Bl':tf.range(k,bl),'Br':tf.range(bl,br)}\n",
    "                    )\n",
    "\n",
    "    model.initPriorNetworks(U_KFBlBr=U_KFBlBr, Z_UF=Z_UF)\n",
    "    model.setModePrior()\n",
    "    return \n",
    "\n",
    "    \n",
    "USE_UNIFORM_PRIOR = False\n",
    "if USE_UNIFORM_PRIOR == True:\n",
    "    model.LatentKappaPrior   = tfp.distributions.Uniform(low=tffloat([-0.5]*pdeState.dimK), high=tffloat([0.5]*pdeState.dimK))#works\n",
    "    model.LatentForcingPrior = tfp.distributions.Uniform(low=tffloat([5.]*pdeState.dimF), high=tffloat([5.]*pdeState.dimF) )\n",
    "\n",
    "USE_NORMAL_PRIOR = True\n",
    "if USE_NORMAL_PRIOR == True:\n",
    "    model.LatentKappaPrior   = tfp.distributions.Normal(tffloat([0.]*pdeState.dimK), tffloat([0.5]*pdeState.dimK))\n",
    "    model.LatentForcingPrior = tfp.distributions.Uniform(low=tffloat([1.]*pdeState.dimF), high=tffloat([5.]*pdeState.dimF) )#works\n",
    "\n",
    "model.LatentBlPrior      = tfp.distributions.Uniform(low=tffloat([0.]), high=tffloat([0.0]))\n",
    "model.LatentBrPrior      = tfp.distributions.Uniform(low=tffloat([0.]), high=tffloat([1.5]) )\n",
    "\n",
    "\n",
    "print(model.LatentForcingPrior.sample())\n",
    "print(model.LatentBlPrior.sample())\n",
    "createNNsPrior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "def computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=True, SAVE=False):\n",
    "    \n",
    "    global totalTimeNNSolving\n",
    "    global totalTimeSolving  \n",
    "    \n",
    "    startSolving = time.time()\n",
    "    meanSamplesU, logVarSamplesU = model.priorModels['U_of_KFBlBr'].Map([samplesK, samplesF, samplesBcl, samplesBcr])\n",
    "    endSolving = time.time()\n",
    "    totalTimeNNSolving += endSolving - startSolving\n",
    "\n",
    "    us = model.reparameterize(meanSamplesU, logVarSamplesU )\n",
    "\n",
    "    residualsU = tf.constant(0., shape=[1])\n",
    "    residualsK = tf.constant(0., shape=[1])\n",
    "    residualsB = tf.constant(0., shape=[1])\n",
    "    \n",
    "    if PLOT == True:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, sharex=True,\n",
    "                                            figsize=(24, 4))\n",
    "    \n",
    "    for i in range(samplesK.shape[0]):\n",
    "\n",
    "        pdeState.kappa   = samplesK[i,:] \n",
    "        pdeState.forcing = samplesF[i,:] \n",
    "        pdeState.bdLeft  = samplesBcl[i,0] \n",
    "        pdeState.bdRight = samplesBcr[i,0] \n",
    "\n",
    "        startSolving = time.time()\n",
    "        u_true     = solver.solve_tf_bfgs(  )\n",
    "        u_trueSpec = solver.solve_tf_FESpectral_bfgs( )\n",
    "        u_trueSpec = pdeState.u_funXFE( u_trueSpec[:,None] )\n",
    "        endSolving = time.time()\n",
    "        totalTimeSolving += endSolving - startSolving\n",
    "\n",
    "        meanU, diagVarU = pdeState.gaussChebyGaussCoeffs(meanSamplesU[i,:], tf.exp(logVarSamplesU[i,:]), xFE )\n",
    "        std2U = 2.*tf.sqrt(diagVarU)\n",
    "        \n",
    "        startSolving = time.time()\n",
    "        uField = pdeState.u_funXFE(us[i,:][:,None])\n",
    "        endSolving = time.time()\n",
    "        totalTimeNNSolving += endSolving - startSolving\n",
    "\n",
    "        kappaField = pdeState.kappa_fun( xFE )\n",
    "\n",
    "        U_true_coeffs = pdeState.getChebyCoeffs_fromPoints(xFE, uField, model.dimU - 1)\n",
    "\n",
    "        ZCoeffReconstMean, ZCoeffReconstlogvar = model.priorModels['Z_of_UF'].Map([ U_true_coeffs[None,:], samplesF[i,:][None,:]])\n",
    "        kappaCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.priorModels['Z_of_UF'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstMean =  tf.reshape(kappaCoeffReconstMean,[-1])\n",
    "        kappaCoeffReconstVar  =  tf.exp(tf.reshape(kappaCoeffReconstlogVar,[-1]))\n",
    "        meanK, diagCovK = pdeState.gaussChebyGaussCoeffs(kappaCoeffReconstMean,kappaCoeffReconstVar, xFE)\n",
    "        meanKT, varKT = pdeState.unscentedGaussTransf(meanK, diagCovK, pdeState.kappaBij, k=2)\n",
    "        std2KT = 2*tf.sqrt(varKT)\n",
    "        print('std2KT = ', std2KT)\n",
    "\n",
    "        BlReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Bl'], axis=1)\n",
    "        BrReconst = tf.gather(ZCoeffReconstMean, model.priorModels['Z_of_UF'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        residualUi = ( tf.linalg.norm(  u_true - meanU ) / tf.linalg.norm( u_true ) )**2.\n",
    "        residualKi = ( tf.linalg.norm( kappaField - meanKT ) / tf.linalg.norm( kappaField ) )**2.\n",
    "        residualBi = ( tf.linalg.norm( ( BlReconst - samplesBcl[i,0] ) + ( samplesBcr[i,0] - BrReconst ) ) / tf.linalg.norm( samplesBcl[i,0] + samplesBcr[i,0] ) )**2.\n",
    "\n",
    "        residualsU = tf.concat([residualsU, residualUi[None]], 0)\n",
    "        residualsK = tf.concat([residualsK, residualKi[None]], 0)\n",
    "        residualsB = tf.concat([residualsB, residualBi[None]], 0)\n",
    "\n",
    "        \n",
    "        if PLOT == True:\n",
    "            ax[0].plot( xFE , u_true)\n",
    "            ax[0].set_xlabel(r'$x$')\n",
    "            ax[0].set_ylabel(r'$u(x)$')\n",
    "            ax[0].set_title('FE Solver')\n",
    "            \n",
    "            ax[1].plot(xFE, meanU)\n",
    "            ax[1].fill_between(xFE, meanU + std2U, meanU - std2U, alpha=0.2)\n",
    "            ax[1].set_xlabel(r'$x$')\n",
    "            ax[1].set_ylabel(r'$u(x) \\pm 2\\sigma$')\n",
    "            ax[1].set_title('NN Solver')\n",
    "\n",
    "            ax[2].plot( xFE, kappaField)\n",
    "            ax[2].set_xlabel(r'$x$')\n",
    "            ax[2].set_ylabel(r'$\\kappa(x)$')\n",
    "            ax[2].set_title(r'True $\\kappa(x)$')\n",
    "            \n",
    "            ax[3].plot(xFE, meanKT)\n",
    "            ax[3].fill_between(xFE, meanKT + std2KT, meanKT- std2KT, alpha=0.2)\n",
    "            ax[3].set_xlabel(r'$x$')\n",
    "            ax[3].set_ylabel(r'$\\kappa(x) \\pm 2\\sigma$')\n",
    "            ax[3].set_title(r'Reconstructed $\\kappa(x)$')\n",
    "\n",
    "            ax[4].plot( xFE , tf.squeeze(pdeState.forcing_funXFE()))\n",
    "            ax[4].set_xlabel(r'$x$')\n",
    "            ax[4].set_ylabel(r'$f(x)$')\n",
    "            ax[4].set_title(r'Forcing')\n",
    "\n",
    "\n",
    "    if PLOT == True:\n",
    "        plt.tight_layout()\n",
    "        if SAVE == True:\n",
    "            plt.savefig('figs/OneDpoissonNONLinearInRangeSolves.pdf')\n",
    "        plt.show()\n",
    "\n",
    "    return residualsU, residualsK, residualsB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSample = 3\n",
    "PLOT = True\n",
    "sampleKGenerator = model.LatentKappaPrior\n",
    "samplesK   = sampleKGenerator.sample(sample_shape=(numSample))\n",
    "\n",
    "samplesF   = model.LatentForcingPrior.sample(sample_shape=(numSample))\n",
    "samplesBcl = model.LatentBlPrior.sample(sample_shape=(numSample))\n",
    "samplesBcr = model.LatentBrPrior.sample(sample_shape=(numSample))\n",
    "\n",
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "residualsU, residualsK, residualsB = computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=PLOT, SAVE=False)\n",
    "\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps =1e-2\n",
    "\n",
    "AllEpsU = []\n",
    "AllEpsK = []\n",
    "AllEpsB = []\n",
    "\n",
    "totalTimeTraining  = 0.\n",
    "\n",
    "trainModels      = True\n",
    "\n",
    "\n",
    "intervalELBOsave = 1000\n",
    "\n",
    "PLOT = True\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_prior(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = model.compute_nelbo_prior(iteration)\n",
    "    for priorvars in model.priorModels['trainable_variables']:\n",
    "        gradients    = tape.gradient(loss, priorvars)\n",
    "        gradients, globNorm = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        tf.debugging.check_numerics(gradients[0], \"GRAD NOT FINITE\")\n",
    "        optimizer.apply_gradients(zip(gradients, priorvars))\n",
    "    return loss\n",
    "\n",
    "if trainModels:\n",
    "       \n",
    "    '''Optimization sequence'''\n",
    "    model.n_sgd      = 1\n",
    "\n",
    "    num_iterations   = tfint(500_000)\n",
    "\n",
    "    model.epsilon_r.assign( tffloat(eps) )\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        1e-3, int(num_iterations/8), 0.5, staircase=True, name=None\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam( lr )\n",
    "\n",
    "    elboAll     = []\n",
    "    startTraining = time.time()\n",
    "    for epoch in tf.range(0, num_iterations ):\n",
    "\n",
    "        start_time = time.time()\n",
    "        loss = train_step_prior(optimizer, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % intervalELBOsave == 0:\n",
    "            #tf.print('epsi_r = ', model.epsilon_r)\n",
    "            elboAll.append(-loss)\n",
    "            print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "                .format(epoch, -loss, end_time - start_time))\n",
    "\n",
    "    endTraining = time.time()\n",
    "    totalTimeTraining += endTraining - startTraining\n",
    "    print(\"DONE TRAINING FOR EPSI\", eps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If you want to load Model Weights'''\n",
    "saveModelWeights = False\n",
    "loadModelWeights = False\n",
    "dirname = 'weightsModel-100/'\n",
    "if saveModelWeights:\n",
    "    print('MODEL WEIGHTS SAVED')\n",
    "    \n",
    "    os.makedirs(os.path.dirname(dirname), exist_ok=True)\n",
    "    model.priorModels['U_of_KFBlBr'].NN.save_weights(dirname+'U_of_KFBlBr_weights.h5')\n",
    "    model.priorModels['Z_of_UF'].NN.save_weights(dirname+'Z_of_UF_weights.h5')\n",
    "    \n",
    "    model.priorModels['U_of_KFBlBr'].NN.compile() \n",
    "    model.priorModels['Z_of_UF'].NN.compile()\n",
    "    model.priorModels['U_of_KFBlBr'].NN.save(dirname+'U_of_KFBlBr_weights.model')\n",
    "    model.priorModels['Z_of_UF'].NN.save(dirname+'Z_of_UF_weights.model')\n",
    "\n",
    "if loadModelWeights:\n",
    "    print('LOADED WEIGHTS SAVED')\n",
    "    dirname = 'weightsModel-100/'\n",
    "    model.priorModels['U_of_KFBlBr'].NN = tf.keras.models.load_model(dirname+'U_of_KFBlBr_weights.model')\n",
    "    model.priorModels['Z_of_UF'].NN = tf.keras.models.load_model(dirname+'Z_of_UF_weights.model')\n",
    "\n",
    "    model.priorModels['U_of_KFBlBr'].NN.compile()\n",
    "    model.priorModels['Z_of_UF'].NN.compile()\n",
    "    # Check its architecture\n",
    "    model.priorModels['U_of_KFBlBr'].NN.summary()\n",
    "    model.priorModels['Z_of_UF'].NN.summary()\n",
    "\n",
    "\n",
    "#print(elboAll)\n",
    "if trainModels:\n",
    "    elboAll =  np.array(elboAll)\n",
    "    np.savetxt('ELBOValsModel', elboAll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'totalTimeTraining = ', totalTimeTraining)\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSample  = 3\n",
    "samplesK   = model.LatentKappaPrior.sample(sample_shape=(numSample))\n",
    "samplesF   = model.LatentForcingPrior.sample(sample_shape=(numSample))\n",
    "samplesBcl = model.LatentBlPrior.sample(sample_shape=(numSample))\n",
    "samplesBcr = model.LatentBrPrior.sample(sample_shape=(numSample))\n",
    "\n",
    "totalTimeNNSolving = 0.\n",
    "totalTimeSolving   = 0. \n",
    "\n",
    "residualsU, residualsK, residualsB = computeSolve_TrueVsNN(samplesK, samplesF, samplesBcl, samplesBcr, PLOT=PLOT, SAVE=False)\n",
    "\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(elboAll.shape[0]),  elboAll )\n",
    "scale = 1e3\n",
    "plt.ylim(-scale,scale)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Times.txt', 'w') as the_file:\n",
    "    the_file.write('totalTimeTraining = '  + str(totalTimeTraining) + 's'+ '\\n' )\n",
    "    the_file.write('totalTimeSolving = '  + str(totalTimeSolving) + 's'+  '\\n' )\n",
    "    the_file.write('totalTimeNNSolving = ' + str(totalTimeNNSolving) + 's'+  '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataYEpsi =tffloat(0.005)\n",
    "def missingPhysics(u, x):\n",
    "    #return u\n",
    "    return u * (tf.math.sin(x*20.) / 20. + 1.) \n",
    "def addIndtNoise(u):\n",
    "    return u + tf.random.normal(stddev=dataYEpsi, shape=u.shape, dtype=floatf)\n",
    "\n",
    "def plotTrueSlnSamples(samplesK, samplesF, samplesBcl, samplesBcr):\n",
    "    \n",
    "    fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(nrows=1, ncols=5, sharex=False,\n",
    "                                        figsize=(20, 3))\n",
    "    \n",
    "    u_All = tf.constant(0., shape=[1, model.dimY], dtype=floatf)\n",
    "\n",
    "    dirname = 'figs/nonlinMissPhysDatset'\n",
    "\n",
    "    for i in range(samplesK.shape[0]):\n",
    "        \n",
    "        model.pdeState.forcing = tf.reshape(samplesF[i,:], [-1]) \n",
    "        model.pdeState.kappa   = tf.reshape(samplesK[i,:], [-1]) \n",
    "        model.pdeState.bdLeft  = tf.reshape(samplesBcl[i,:], []) \n",
    "        model.pdeState.bdRight = tf.reshape(samplesBcr[i,:], []) \n",
    "\n",
    "        u_true     = solver.solve_tf_bfgs(  )\n",
    "        u_missPhys = missingPhysics(u_true, xFE)\n",
    "        u_missPhysNoise = addIndtNoise(u_missPhys)\n",
    "        u_All = tf.concat([u_All,u_missPhysNoise[None,:] ], 0)\n",
    "\n",
    "        ax0.plot( pdeState.xFE, u_missPhys)\n",
    "        ax1.plot(pdeState.xFE,u_missPhysNoise)\n",
    "        ax2.plot(pdeState.xFE, u_true)\n",
    "        ax3.plot(pdeState.xFE, u_missPhysNoise - u_true)\n",
    "\n",
    "        kappaField = pdeState.kappa_fun(xFE)\n",
    "        ax4.plot( xFE, kappaField )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    extent = ax1.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('{}Datay.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax2.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('{}TrueSol.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax3.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('{}TrueRho.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    extent = ax4.get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig('{}TrueKappa.pdf'.format(dirname), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "    plt.show()\n",
    "    u_All = u_All[1:,:]\n",
    "    return u_All\n",
    "\n",
    "model.dimY = pdeState.xFE.shape[0]\n",
    "\n",
    "numData = 50\n",
    "print('model.dimK = ', model.dimK)\n",
    "samplesKdata   = model.LatentKappaPrior.sample(sample_shape=(numData))\n",
    "samplesFdata   = model.LatentForcingPrior.sample(sample_shape=(numData))\n",
    "samplesBldata  = model.LatentBlPrior.sample(sample_shape=(numData))\n",
    "samplesBrdata  = model.LatentBrPrior.sample(sample_shape=(numData))\n",
    "\n",
    "\n",
    "priorFEpsi = tf.constant(1e-3,dtype=floatf)\n",
    "priorMeanF = samplesFdata + tf.random.normal(stddev=priorFEpsi,  shape=samplesFdata.shape, dtype=floatf)\n",
    "priorStdF  = tf.tile(priorFEpsi[None,None], priorMeanF.shape)\n",
    "model.dataForcingPrior = (priorMeanF, tf.math.log(priorStdF)*2 )\n",
    "\n",
    "variableSTD = tffloat(1e-1)\n",
    "\n",
    "priorKEpsi = variableSTD\n",
    "priorMeanK = samplesKdata \n",
    "priorStdK  = tf.tile(priorKEpsi[None,None], priorMeanK.shape)\n",
    "model.dataKappaPrior = (priorMeanK,  tf.math.log(priorStdK)*2)\n",
    "\n",
    "priorBlEpsi = variableSTD\n",
    "priorMeanBl = samplesBldata \n",
    "priorStdBl  = tf.tile(priorBlEpsi[None,None], priorMeanBl.shape)\n",
    "model.dataBlPrior = (priorMeanBl,  tf.math.log(priorStdBl)*2)\n",
    "\n",
    "priorBrEpsi = variableSTD\n",
    "priorMeanBr = samplesBrdata \n",
    "priorStdBr  = tf.tile(priorBrEpsi[None,None], priorMeanBr.shape)\n",
    "model.dataBrPrior = (priorMeanBr,  tf.math.log(priorStdBr)*2)\n",
    "\n",
    "model.dataY = plotTrueSlnSamples(samplesKdata, samplesFdata, samplesBldata, samplesBrdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"{}ModelDataset\".format(dirname), model.dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNNsPost():\n",
    "    \n",
    "    nh = 200 \n",
    "\n",
    "    Y_U     = NeuralN('Y_of_U',\n",
    "                np.array([model.dimU,\n",
    "                            nh,\n",
    "                            model.dimY]),\n",
    "                )\n",
    "\n",
    "\n",
    "    k  = model.dimK\n",
    "    bl = k  + model.dimBl\n",
    "    br = bl + model.dimBr\n",
    "    dimKBlBr = model.dimK + model.dimBl + model.dimBr\n",
    "    KBlBr_Y  = NeuralN('KBlBr_of_Y', \n",
    "                    np.array([model.dimY,\n",
    "                              nh,\n",
    "                              dimKBlBr]),\n",
    "                        multOutputLayout = {'K': tf.range(0,k),\n",
    "                                            'Bl':tf.range(k,bl),'Br':tf.range(bl,br)}\n",
    "                    )\n",
    "\n",
    "\n",
    "    model.initPostNetworks( Y_U=Y_U, KBlBr_Y=KBlBr_Y)\n",
    "    model.setModePost()\n",
    "    return \n",
    "\n",
    "createNNsPost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "totalTimeTrainingPost  = 0.\n",
    "\n",
    "trainModels      = True\n",
    "\n",
    "\n",
    "intervalELBOsave = 1000\n",
    "\n",
    "PLOT = False\n",
    "\n",
    "model.epsilon_y.assign(tffloat(0.1)) \n",
    "\n",
    "model.setModePost()\n",
    "\n",
    "timeStartTraingPost = time.time()\n",
    "\n",
    "clipELBO = tfb.SoftClip(low=tffloat(-1000.), high=tffloat(1000.), hinge_softness=5.)\n",
    "loss = model.compute_nelbo_post(0)\n",
    "@tf.function\n",
    "def train_step_post(optimizer, iteration):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss = model.compute_nelbo_post(iteration)\n",
    "    for postvars in model.postModels['trainable_variables']:\n",
    "        gradients = tape.gradient(loss, postvars)\n",
    "        gradients, globNorm = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        tf.debugging.check_numerics(gradients[0], \"GRAD NOT FINITE\")\n",
    "        optimizer.apply_gradients(zip(gradients, postvars))\n",
    "    return loss\n",
    "\n",
    "\n",
    "if trainModels:\n",
    "    \n",
    "    createNNsPost()\n",
    "    \n",
    "    '''Optimization sequence'''\n",
    "    model.n_sgd      = 1\n",
    "\n",
    "    num_iterations   = tfint(500_000)\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        1e-3, int(num_iterations/5), 0.5, staircase=True, name=None\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam( lr )\n",
    "\n",
    "    elboAll     = []\n",
    "    startTraining = time.time()\n",
    "    for epoch in tf.range(0, num_iterations ):\n",
    "\n",
    "        start_time = time.time()\n",
    "        loss = train_step_post(optimizer, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % intervalELBOsave == 0:\n",
    "            #tf.print('epsi_r = ', model.epsilon_r)\n",
    "            elboAll.append(-loss)\n",
    "            print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "                .format(epoch, -loss, end_time - start_time))\n",
    "\n",
    "    endTraining = time.time()\n",
    "    totalTimeTraining += endTraining - startTraining\n",
    "    print(\"DONE TRAINING FOR EPSI\", eps)\n",
    "\n",
    "timeEndTraingPost = time.time()\n",
    "print('timeTakenTraining = ', timeEndTraingPost - timeStartTraingPost )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModelWeights = False\n",
    "loadModelWeights = False\n",
    "'''If you want to load Model Weights'''\n",
    "\n",
    "if loadModelWeights:\n",
    "    dirname = 'weightsModel-100/'.format(eps)\n",
    "    model.postModels['KBlBr_of_Y'].NN.load_weights(dirname+'/KBlBr_of_Y_weights.h5')\n",
    "    model.postModels['Y_of_U'].NN.load_weights(dirname+'/Y_of_U_weights.h5')\n",
    "\n",
    "    model.postModels['KBlBr_of_Y'].NN.compile()\n",
    "    model.postModels['Y_of_U'].NN.compile()\n",
    "    # Check its architecture\n",
    "    model.postModels['KBlBr_of_Y'].NN.summary()\n",
    "    model.postModels['Y_of_U'].NN.summary()\n",
    "    print(\"LOADED WEIGHTS\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if saveModelWeights:\n",
    "    dirname = 'weightsModel-100/'.format(eps)\n",
    "    os.makedirs(os.path.dirname(dirname), exist_ok=True)\n",
    "    model.postModels['KBlBr_of_Y'].NN.save_weights(dirname+'/KBlBr_of_Y_weights.h5')\n",
    "    model.postModels['Y_of_U'].NN.save_weights(dirname+'/Y_of_U_weights.h5')\n",
    "    print(\"SAVED WEIGHTS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(elboAll)\n",
    "if trainModels:\n",
    "    elboAll =  np.array(elboAll)\n",
    "    np.savetxt('ELBOValsModel-{}epsi'.format(eps), elboAll)\n",
    "\n",
    "print( 'totalTimeTraining = ', totalTimeTraining)\n",
    "print( 'totalTimeSolving = ', totalTimeSolving)\n",
    "print( 'totalTimeNNSolving = ', totalTimeNNSolving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataYEpsi =tffloat(0.005)\n",
    "def missingPhysics(u, x):\n",
    "    #return u\n",
    "    return u * (tf.math.sin(x*20.) / 20. + 1.) \n",
    "def addIndtNoise(u):\n",
    "    return u + tf.random.normal(stddev=dataYEpsi, shape=u.shape, dtype=floatf)\n",
    "\n",
    "def plotTrueSlnSamplesPost(samplesK, samplesF, samplesBcl, samplesBcr, SAVE=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=4, sharex=False,\n",
    "                                        figsize=(20, 8))\n",
    "    \n",
    "    u_All = tf.constant(0., shape=[1, model.dimY], dtype=floatf)\n",
    "\n",
    "    for i in range(samplesK.shape[0]):\n",
    "        \n",
    "        model.pdeState.forcing =  tf.reshape(samplesF[i,:], [-1]) \n",
    "        model.pdeState.kappa   =  tf.reshape(samplesK[i,:], [-1]) \n",
    "        model.pdeState.bdLeft  =  tf.reshape(samplesBcl[i,:], []) \n",
    "        model.pdeState.bdRight =  tf.reshape(samplesBcr[i,:], []) \n",
    "\n",
    "        u_prior = solver.solve_tf_bfgs( )\n",
    "        u_missPhys = missingPhysics(u_prior, xFE)\n",
    "        u_missPhysNoise = addIndtNoise(u_missPhys)\n",
    "        u_All = tf.concat([u_All,u_missPhysNoise[None,:] ], 0)\n",
    "\n",
    "        ax[0,0].plot(pdeState.xFE,u_missPhysNoise)\n",
    "\n",
    "        ax[0,1].plot(pdeState.xFE, u_prior)\n",
    "        \n",
    "        ax[0,2].plot(pdeState.xFE, u_missPhysNoise - u_prior)\n",
    "        ax[0,2].set_ylim(-0.25, 0.25)\n",
    "\n",
    "        kappaField = pdeState.kappa_fun(xFE)\n",
    "        ax[0,3].plot( pdeState.xFE, kappaField )\n",
    "        \n",
    "        ZCoeffReconstMean, ZCoeffReconstlogvar = model.postModels['KBlBr_of_Y'].Map([ u_missPhysNoise[None,:]])\n",
    "\n",
    "        kappaCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.postModels['KBlBr_of_Y'].multOutputLayout['K'], axis=1)\n",
    "        kappaCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.postModels['KBlBr_of_Y'].multOutputLayout['K'], axis=1)\n",
    "\n",
    "        BLCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.postModels['KBlBr_of_Y'].multOutputLayout['Bl'], axis=1)\n",
    "        BLCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.postModels['KBlBr_of_Y'].multOutputLayout['Bl'], axis=1)\n",
    "\n",
    "        BRCoeffReconstMean = tf.gather(ZCoeffReconstMean, model.postModels['KBlBr_of_Y'].multOutputLayout['Br'], axis=1)\n",
    "        BRCoeffReconstlogVar  = tf.gather(ZCoeffReconstlogvar, model.postModels['KBlBr_of_Y'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        kappaCoeffReconstMean =  tf.reshape(kappaCoeffReconstMean,[-1])\n",
    "        kappaCoeffReconstVar  =  tf.exp(tf.reshape(kappaCoeffReconstlogVar,[-1]))\n",
    "        meanK, diagCovK = pdeState.gaussChebyGaussCoeffs(kappaCoeffReconstMean,kappaCoeffReconstVar, xFE)\n",
    "        meanKT, varKT = pdeState.unscentedGaussTransf(meanK, diagCovK, pdeState.kappaBij, k=1)\n",
    "        std2KT = 2*tf.sqrt(varKT)\n",
    "\n",
    "        BlReconst = tf.gather(ZCoeffReconstMean, model.postModels['KBlBr_of_Y'].multOutputLayout['Bl'], axis=1)\n",
    "        BrReconst = tf.gather(ZCoeffReconstMean, model.postModels['KBlBr_of_Y'].multOutputLayout['Br'], axis=1)\n",
    "\n",
    "        # meanSamplesU, logVarSamplesU = model.priorModels['U_of_KFBlBr'].Map([samplesK[i,:][None,:], samplesF[i,:][None,:], samplesBcl[i,:][None,:], samplesBcr[i,:][None,:]])\n",
    "        meanSamplesU, logVarSamplesU = model.priorModels['U_of_KFBlBr'].Map([tf.reshape(kappaCoeffReconstMean, [1,-1]), samplesF[i,:][None,:], BLCoeffReconstMean, BRCoeffReconstMean])\n",
    "        us = model.reparameterize(meanSamplesU, logVarSamplesU )\n",
    "\n",
    "        meanU, diagVarU = pdeState.gaussChebyGaussCoeffs(meanSamplesU[0,:], tf.exp(logVarSamplesU[0,:]), xFE )\n",
    "        std2U = 2.*tf.sqrt(diagVarU)\n",
    "\n",
    "        YReconstMean, YreconLogVar = model.postModels['Y_of_U'].Map([tf.reshape(meanSamplesU[0,:], [1,-1])])  \n",
    "        std2YT = 2*tf.sqrt(YreconLogVar)\n",
    "\n",
    "        ax[1,0].plot(pdeState.xFE, YReconstMean[0,:])\n",
    "        ax[1,0].fill_between(pdeState.xFE, YReconstMean[0,:] - std2YT[0,:], YReconstMean[0,:] + std2YT[0,:], alpha=0.2)\n",
    "\n",
    "        ax[1,1].plot(pdeState.xFE, meanU)\n",
    "        ax[1,1].fill_between(pdeState.xFE, meanU - std2U, meanU + std2U, alpha=0.2)\n",
    "\n",
    "        ax[1,2].plot(pdeState.xFE, YReconstMean[0,:] - meanU)\n",
    "        ax[1,1].fill_between(pdeState.xFE, (YReconstMean[0,:] - meanU) - (std2U+std2YT[0,:]),  (YReconstMean[0,:] - meanU) + (std2U+std2YT[0,:]), alpha=0.2)\n",
    "        ax[1,2].set_ylim(-0.25, 0.25)\n",
    "\n",
    "        ax[1,3].plot(pdeState.xFE, meanKT)\n",
    "        ax[1,3].fill_between(pdeState.xFE, meanKT - std2KT, meanKT + std2KT, alpha=0.2)\n",
    "\n",
    " \n",
    "    plt.tight_layout()\n",
    "    if SAVE is not None:\n",
    "        plt.tight_layout()\n",
    "        extent = ax[0, 0].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-Datay.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 1].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-TrueSol.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 2].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-TrueRho.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[0, 3].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-TrueKappa.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 0].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-Reconstructedy.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 1].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-ReconstructedSol.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 2].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-ReconstructedRho.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        extent = ax[1, 3].get_tightbbox(fig.canvas.renderer).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig('figs/{}-ReconstructedKappa.pdf'.format(SAVE), bbox_inches=extent.expanded(1.01, 1.01))\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig('MissingPhysFig{}.pdf'.format(SAVE))\n",
    "    plt.show()\n",
    "\n",
    "    u_All = u_All[1:,:]\n",
    "    return u_All\n",
    "\n",
    "\n",
    "#model.dataY = plotTrueSlnSamplesPost(samplesKdata, samplesFdata, samplesBldata, samplesBrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numData = 5\n",
    "\n",
    "samplesKdataPost   = model.LatentKappaPrior.sample(sample_shape=(numData))\n",
    "samplesFdataPost   = model.LatentForcingPrior.sample(sample_shape=(numData))\n",
    "samplesFdataPost   = tf.reshape(tf.linspace(1., 5., 5), [-1, 1])\n",
    "samplesBldataPost  = model.LatentBlPrior.sample(sample_shape=(numData))\n",
    "samplesBrdataPost  = model.LatentBrPrior.sample(sample_shape=(numData))\n",
    "\n",
    "\n",
    "plotTrueSlnSamplesPost(samplesKdataPost, samplesFdataPost, samplesBldataPost, samplesBrdataPost, SAVE=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f27e755c6e9f953092984d2fa7d5cd43e84a5cfdd14fc533980b318a0988c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
